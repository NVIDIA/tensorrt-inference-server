// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: server_status.proto

package nvidia.inferenceserver;

public final class ServerStatusOuterClass {
  private ServerStatusOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:enum:: ModelReadyState
   *&#64;&#64;
   *&#64;&#64;   Readiness status for models.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf enum {@code nvidia.inferenceserver.ModelReadyState}
   */
  public enum ModelReadyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNKNOWN = 0
     *&#64;&#64;
     *&#64;&#64;     The model is in an unknown state. The model is not available for
     *&#64;&#64;     inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNKNOWN = 0;</code>
     */
    MODEL_UNKNOWN(0),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_READY = 1
     *&#64;&#64;
     *&#64;&#64;     The model is ready and available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_READY = 1;</code>
     */
    MODEL_READY(1),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNAVAILABLE = 2
     *&#64;&#64;
     *&#64;&#64;     The model is unavailable, indicating that the model failed to
     *&#64;&#64;     load or has been implicitly or explicitly unloaded. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNAVAILABLE = 2;</code>
     */
    MODEL_UNAVAILABLE(2),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_LOADING = 3
     *&#64;&#64;
     *&#64;&#64;     The model is being loaded by the inference server. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_LOADING = 3;</code>
     */
    MODEL_LOADING(3),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNLOADING = 4
     *&#64;&#64;
     *&#64;&#64;     The model is being unloaded by the inference server. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNLOADING = 4;</code>
     */
    MODEL_UNLOADING(4),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNKNOWN = 0
     *&#64;&#64;
     *&#64;&#64;     The model is in an unknown state. The model is not available for
     *&#64;&#64;     inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNKNOWN = 0;</code>
     */
    public static final int MODEL_UNKNOWN_VALUE = 0;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_READY = 1
     *&#64;&#64;
     *&#64;&#64;     The model is ready and available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_READY = 1;</code>
     */
    public static final int MODEL_READY_VALUE = 1;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNAVAILABLE = 2
     *&#64;&#64;
     *&#64;&#64;     The model is unavailable, indicating that the model failed to
     *&#64;&#64;     load or has been implicitly or explicitly unloaded. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNAVAILABLE = 2;</code>
     */
    public static final int MODEL_UNAVAILABLE_VALUE = 2;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_LOADING = 3
     *&#64;&#64;
     *&#64;&#64;     The model is being loaded by the inference server. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_LOADING = 3;</code>
     */
    public static final int MODEL_LOADING_VALUE = 3;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ModelReadyState::MODEL_UNLOADING = 4
     *&#64;&#64;
     *&#64;&#64;     The model is being unloaded by the inference server. The model is
     *&#64;&#64;     not available for inferencing.
     *&#64;&#64;
     * </pre>
     *
     * <code>MODEL_UNLOADING = 4;</code>
     */
    public static final int MODEL_UNLOADING_VALUE = 4;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModelReadyState valueOf(int value) {
      return forNumber(value);
    }

    public static ModelReadyState forNumber(int value) {
      switch (value) {
        case 0: return MODEL_UNKNOWN;
        case 1: return MODEL_READY;
        case 2: return MODEL_UNAVAILABLE;
        case 3: return MODEL_LOADING;
        case 4: return MODEL_UNLOADING;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModelReadyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ModelReadyState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModelReadyState>() {
            public ModelReadyState findValueByNumber(int number) {
              return ModelReadyState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.getDescriptor().getEnumTypes().get(0);
    }

    private static final ModelReadyState[] VALUES = values();

    public static ModelReadyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModelReadyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:nvidia.inferenceserver.ModelReadyState)
  }

  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:enum:: ServerReadyState
   *&#64;&#64;
   *&#64;&#64;   Readiness status for the inference server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf enum {@code nvidia.inferenceserver.ServerReadyState}
   */
  public enum ServerReadyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_INVALID = 0
     *&#64;&#64;
     *&#64;&#64;     The server is in an invalid state and will likely not
     *&#64;&#64;     response correctly to any requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_INVALID = 0;</code>
     */
    SERVER_INVALID(0),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_INITIALIZING = 1
     *&#64;&#64;
     *&#64;&#64;     The server is initializing.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_INITIALIZING = 1;</code>
     */
    SERVER_INITIALIZING(1),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_READY = 2
     *&#64;&#64;
     *&#64;&#64;     The server is ready and accepting requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_READY = 2;</code>
     */
    SERVER_READY(2),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_EXITING = 3
     *&#64;&#64;
     *&#64;&#64;     The server is exiting and will not respond to requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_EXITING = 3;</code>
     */
    SERVER_EXITING(3),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_FAILED_TO_INITIALIZE = 10
     *&#64;&#64;
     *&#64;&#64;     The server did not initialize correctly. Most requests will fail.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_FAILED_TO_INITIALIZE = 10;</code>
     */
    SERVER_FAILED_TO_INITIALIZE(10),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_INVALID = 0
     *&#64;&#64;
     *&#64;&#64;     The server is in an invalid state and will likely not
     *&#64;&#64;     response correctly to any requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_INVALID = 0;</code>
     */
    public static final int SERVER_INVALID_VALUE = 0;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_INITIALIZING = 1
     *&#64;&#64;
     *&#64;&#64;     The server is initializing.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_INITIALIZING = 1;</code>
     */
    public static final int SERVER_INITIALIZING_VALUE = 1;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_READY = 2
     *&#64;&#64;
     *&#64;&#64;     The server is ready and accepting requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_READY = 2;</code>
     */
    public static final int SERVER_READY_VALUE = 2;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_EXITING = 3
     *&#64;&#64;
     *&#64;&#64;     The server is exiting and will not respond to requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_EXITING = 3;</code>
     */
    public static final int SERVER_EXITING_VALUE = 3;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: ServerReadyState::SERVER_FAILED_TO_INITIALIZE = 10
     *&#64;&#64;
     *&#64;&#64;     The server did not initialize correctly. Most requests will fail.
     *&#64;&#64;
     * </pre>
     *
     * <code>SERVER_FAILED_TO_INITIALIZE = 10;</code>
     */
    public static final int SERVER_FAILED_TO_INITIALIZE_VALUE = 10;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ServerReadyState valueOf(int value) {
      return forNumber(value);
    }

    public static ServerReadyState forNumber(int value) {
      switch (value) {
        case 0: return SERVER_INVALID;
        case 1: return SERVER_INITIALIZING;
        case 2: return SERVER_READY;
        case 3: return SERVER_EXITING;
        case 10: return SERVER_FAILED_TO_INITIALIZE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ServerReadyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ServerReadyState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ServerReadyState>() {
            public ServerReadyState findValueByNumber(int number) {
              return ServerReadyState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.getDescriptor().getEnumTypes().get(1);
    }

    private static final ServerReadyState[] VALUES = values();

    public static ServerReadyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ServerReadyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:nvidia.inferenceserver.ServerReadyState)
  }

  public interface StatDurationOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.StatDuration)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of times this metric occurred.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 count = 1;</code>
     */
    long getCount();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 total_time_ns
     *&#64;&#64;
     *&#64;&#64;     Total collected duration of this metric in nanoseconds.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 total_time_ns = 2;</code>
     */
    long getTotalTimeNs();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message StatDuration
   *&#64;&#64;
   *&#64;&#64;   Statistic collecting a duration metric.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.StatDuration}
   */
  public  static final class StatDuration extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.StatDuration)
      StatDurationOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StatDuration.newBuilder() to construct.
    private StatDuration(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StatDuration() {
      count_ = 0L;
      totalTimeNs_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StatDuration(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {

              count_ = input.readUInt64();
              break;
            }
            case 16: {

              totalTimeNs_ = input.readUInt64();
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatDuration_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatDuration_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.class, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder.class);
    }

    public static final int COUNT_FIELD_NUMBER = 1;
    private long count_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of times this metric occurred.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 count = 1;</code>
     */
    public long getCount() {
      return count_;
    }

    public static final int TOTAL_TIME_NS_FIELD_NUMBER = 2;
    private long totalTimeNs_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 total_time_ns
     *&#64;&#64;
     *&#64;&#64;     Total collected duration of this metric in nanoseconds.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 total_time_ns = 2;</code>
     */
    public long getTotalTimeNs() {
      return totalTimeNs_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (count_ != 0L) {
        output.writeUInt64(1, count_);
      }
      if (totalTimeNs_ != 0L) {
        output.writeUInt64(2, totalTimeNs_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (count_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, count_);
      }
      if (totalTimeNs_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, totalTimeNs_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.StatDuration)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.StatDuration other = (nvidia.inferenceserver.ServerStatusOuterClass.StatDuration) obj;

      boolean result = true;
      result = result && (getCount()
          == other.getCount());
      result = result && (getTotalTimeNs()
          == other.getTotalTimeNs());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COUNT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getCount());
      hash = (37 * hash) + TOTAL_TIME_NS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getTotalTimeNs());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message StatDuration
     *&#64;&#64;
     *&#64;&#64;   Statistic collecting a duration metric.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.StatDuration}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.StatDuration)
        nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatDuration_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatDuration_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.class, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        count_ = 0L;

        totalTimeNs_ = 0L;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatDuration_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration build() {
        nvidia.inferenceserver.ServerStatusOuterClass.StatDuration result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.StatDuration result = new nvidia.inferenceserver.ServerStatusOuterClass.StatDuration(this);
        result.count_ = count_;
        result.totalTimeNs_ = totalTimeNs_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.StatDuration) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.StatDuration)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance()) return this;
        if (other.getCount() != 0L) {
          setCount(other.getCount());
        }
        if (other.getTotalTimeNs() != 0L) {
          setTotalTimeNs(other.getTotalTimeNs());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.StatDuration parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.StatDuration) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private long count_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of times this metric occurred.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 count = 1;</code>
       */
      public long getCount() {
        return count_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of times this metric occurred.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 count = 1;</code>
       */
      public Builder setCount(long value) {
        
        count_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of times this metric occurred.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 count = 1;</code>
       */
      public Builder clearCount() {
        
        count_ = 0L;
        onChanged();
        return this;
      }

      private long totalTimeNs_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 total_time_ns
       *&#64;&#64;
       *&#64;&#64;     Total collected duration of this metric in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 total_time_ns = 2;</code>
       */
      public long getTotalTimeNs() {
        return totalTimeNs_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 total_time_ns
       *&#64;&#64;
       *&#64;&#64;     Total collected duration of this metric in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 total_time_ns = 2;</code>
       */
      public Builder setTotalTimeNs(long value) {
        
        totalTimeNs_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 total_time_ns
       *&#64;&#64;
       *&#64;&#64;     Total collected duration of this metric in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 total_time_ns = 2;</code>
       */
      public Builder clearTotalTimeNs() {
        
        totalTimeNs_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.StatDuration)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.StatDuration)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.StatDuration DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.StatDuration();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StatDuration>
        PARSER = new com.google.protobuf.AbstractParser<StatDuration>() {
      @java.lang.Override
      public StatDuration parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StatDuration(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StatDuration> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StatDuration> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StatusRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.StatusRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message StatusRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for Status requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.StatusRequestStats}
   */
  public  static final class StatusRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.StatusRequestStats)
      StatusRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StatusRequestStats.newBuilder() to construct.
    private StatusRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StatusRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StatusRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatusRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Status requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message StatusRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.StatusRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.StatusRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatusRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Status requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.StatusRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.StatusRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StatusRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<StatusRequestStats>() {
      @java.lang.Override
      public StatusRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StatusRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StatusRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StatusRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HealthRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.HealthRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message HealthRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for Health requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.HealthRequestStats}
   */
  public  static final class HealthRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.HealthRequestStats)
      HealthRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use HealthRequestStats.newBuilder() to construct.
    private HealthRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private HealthRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private HealthRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_HealthRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Health requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message HealthRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.HealthRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.HealthRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_HealthRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Health requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.HealthRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.HealthRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<HealthRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<HealthRequestStats>() {
      @java.lang.Override
      public HealthRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new HealthRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<HealthRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<HealthRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelControlRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelControlRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelControlRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for ModelControl requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ModelControlRequestStats}
   */
  public  static final class ModelControlRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelControlRequestStats)
      ModelControlRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModelControlRequestStats.newBuilder() to construct.
    private ModelControlRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelControlRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModelControlRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelControlRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful ModelControl requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelControlRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelControlRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelControlRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelControlRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful ModelControl requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelControlRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelControlRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelControlRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<ModelControlRequestStats>() {
      @java.lang.Override
      public ModelControlRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModelControlRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelControlRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModelControlRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SharedMemoryControlRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.SharedMemoryControlRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message SharedMemoryControlRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for SharedMemoryControl requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.SharedMemoryControlRequestStats}
   */
  public  static final class SharedMemoryControlRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.SharedMemoryControlRequestStats)
      SharedMemoryControlRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SharedMemoryControlRequestStats.newBuilder() to construct.
    private SharedMemoryControlRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SharedMemoryControlRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SharedMemoryControlRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful SharedMemoryControl
     *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message SharedMemoryControlRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.SharedMemoryControlRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.SharedMemoryControlRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful SharedMemoryControl
       *&#64;&#64;     requests, not including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.SharedMemoryControlRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.SharedMemoryControlRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SharedMemoryControlRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<SharedMemoryControlRequestStats>() {
      @java.lang.Override
      public SharedMemoryControlRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SharedMemoryControlRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SharedMemoryControlRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SharedMemoryControlRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RepositoryRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.RepositoryRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message RepositoryRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for Repository requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.RepositoryRequestStats}
   */
  public  static final class RepositoryRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.RepositoryRequestStats)
      RepositoryRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RepositoryRequestStats.newBuilder() to construct.
    private RepositoryRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RepositoryRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private RepositoryRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_RepositoryRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Repository requests, not
     *&#64;&#64;     including HTTP or gRPC endpoint termination time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message RepositoryRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.RepositoryRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.RepositoryRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_RepositoryRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Repository requests, not
       *&#64;&#64;     including HTTP or gRPC endpoint termination time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.RepositoryRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.RepositoryRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RepositoryRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<RepositoryRequestStats>() {
      @java.lang.Override
      public RepositoryRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RepositoryRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RepositoryRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RepositoryRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InferRequestStatsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.InferRequestStats)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    boolean hasSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    boolean hasFailed();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getFailed();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getFailedOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    boolean hasCompute();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getCompute();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getComputeOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    boolean hasQueue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getQueue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getQueueOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message InferRequestStats
   *&#64;&#64;
   *&#64;&#64;   Statistics collected for Infer requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.InferRequestStats}
   */
  public  static final class InferRequestStats extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.InferRequestStats)
      InferRequestStatsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InferRequestStats.newBuilder() to construct.
    private InferRequestStats(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InferRequestStats() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private InferRequestStats(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (success_ != null) {
                subBuilder = success_.toBuilder();
              }
              success_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(success_);
                success_ = subBuilder.buildPartial();
              }

              break;
            }
            case 18: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (failed_ != null) {
                subBuilder = failed_.toBuilder();
              }
              failed_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(failed_);
                failed_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (compute_ != null) {
                subBuilder = compute_.toBuilder();
              }
              compute_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(compute_);
                compute_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder subBuilder = null;
              if (queue_ != null) {
                subBuilder = queue_.toBuilder();
              }
              queue_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(queue_);
                queue_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_InferRequestStats_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_InferRequestStats_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.Builder.class);
    }

    public static final int SUCCESS_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public boolean hasSuccess() {
      return success_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
      return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration success
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle successful Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
      return getSuccess();
    }

    public static final int FAILED_FIELD_NUMBER = 2;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration failed_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    public boolean hasFailed() {
      return failed_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getFailed() {
      return failed_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : failed_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration failed
     *&#64;&#64;
     *&#64;&#64;     Total time required to handle failed Infer requests, not
     *&#64;&#64;     including HTTP or GRPC endpoint handling time.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getFailedOrBuilder() {
      return getFailed();
    }

    public static final int COMPUTE_FIELD_NUMBER = 3;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration compute_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    public boolean hasCompute() {
      return compute_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getCompute() {
      return compute_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : compute_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration compute
     *&#64;&#64;
     *&#64;&#64;     Time required to run inferencing for an inference request;
     *&#64;&#64;     including time copying input tensors to GPU memory, time
     *&#64;&#64;     executing the model, and time copying output tensors from GPU
     *&#64;&#64;     memory.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getComputeOrBuilder() {
      return getCompute();
    }

    public static final int QUEUE_FIELD_NUMBER = 4;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration queue_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    public boolean hasQueue() {
      return queue_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getQueue() {
      return queue_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : queue_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatDuration queue
     *&#64;&#64;
     *&#64;&#64;     Time an inference request waits in scheduling queue for an
     *&#64;&#64;     available model instance.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getQueueOrBuilder() {
      return getQueue();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (success_ != null) {
        output.writeMessage(1, getSuccess());
      }
      if (failed_ != null) {
        output.writeMessage(2, getFailed());
      }
      if (compute_ != null) {
        output.writeMessage(3, getCompute());
      }
      if (queue_ != null) {
        output.writeMessage(4, getQueue());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (success_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSuccess());
      }
      if (failed_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getFailed());
      }
      if (compute_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCompute());
      }
      if (queue_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getQueue());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats other = (nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats) obj;

      boolean result = true;
      result = result && (hasSuccess() == other.hasSuccess());
      if (hasSuccess()) {
        result = result && getSuccess()
            .equals(other.getSuccess());
      }
      result = result && (hasFailed() == other.hasFailed());
      if (hasFailed()) {
        result = result && getFailed()
            .equals(other.getFailed());
      }
      result = result && (hasCompute() == other.hasCompute());
      if (hasCompute()) {
        result = result && getCompute()
            .equals(other.getCompute());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSuccess()) {
        hash = (37 * hash) + SUCCESS_FIELD_NUMBER;
        hash = (53 * hash) + getSuccess().hashCode();
      }
      if (hasFailed()) {
        hash = (37 * hash) + FAILED_FIELD_NUMBER;
        hash = (53 * hash) + getFailed().hashCode();
      }
      if (hasCompute()) {
        hash = (37 * hash) + COMPUTE_FIELD_NUMBER;
        hash = (53 * hash) + getCompute().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message InferRequestStats
     *&#64;&#64;
     *&#64;&#64;   Statistics collected for Infer requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.InferRequestStats}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.InferRequestStats)
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStatsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_InferRequestStats_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_InferRequestStats_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.class, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (successBuilder_ == null) {
          success_ = null;
        } else {
          success_ = null;
          successBuilder_ = null;
        }
        if (failedBuilder_ == null) {
          failed_ = null;
        } else {
          failed_ = null;
          failedBuilder_ = null;
        }
        if (computeBuilder_ == null) {
          compute_ = null;
        } else {
          compute_ = null;
          computeBuilder_ = null;
        }
        if (queueBuilder_ == null) {
          queue_ = null;
        } else {
          queue_ = null;
          queueBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_InferRequestStats_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats build() {
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats result = new nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats(this);
        if (successBuilder_ == null) {
          result.success_ = success_;
        } else {
          result.success_ = successBuilder_.build();
        }
        if (failedBuilder_ == null) {
          result.failed_ = failed_;
        } else {
          result.failed_ = failedBuilder_.build();
        }
        if (computeBuilder_ == null) {
          result.compute_ = compute_;
        } else {
          result.compute_ = computeBuilder_.build();
        }
        if (queueBuilder_ == null) {
          result.queue_ = queue_;
        } else {
          result.queue_ = queueBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.getDefaultInstance()) return this;
        if (other.hasSuccess()) {
          mergeSuccess(other.getSuccess());
        }
        if (other.hasFailed()) {
          mergeFailed(other.getFailed());
        }
        if (other.hasCompute()) {
          mergeCompute(other.getCompute());
        }
        if (other.hasQueue()) {
          mergeQueue(other.getQueue());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration success_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> successBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public boolean hasSuccess() {
        return successBuilder_ != null || success_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getSuccess() {
        if (successBuilder_ == null) {
          return success_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        } else {
          return successBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          success_ = value;
          onChanged();
        } else {
          successBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder setSuccess(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (successBuilder_ == null) {
          success_ = builderForValue.build();
          onChanged();
        } else {
          successBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder mergeSuccess(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (successBuilder_ == null) {
          if (success_ != null) {
            success_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(success_).mergeFrom(value).buildPartial();
          } else {
            success_ = value;
          }
          onChanged();
        } else {
          successBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public Builder clearSuccess() {
        if (successBuilder_ == null) {
          success_ = null;
          onChanged();
        } else {
          success_ = null;
          successBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getSuccessBuilder() {
        
        onChanged();
        return getSuccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getSuccessOrBuilder() {
        if (successBuilder_ != null) {
          return successBuilder_.getMessageOrBuilder();
        } else {
          return success_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : success_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration success
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle successful Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration success = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getSuccessFieldBuilder() {
        if (successBuilder_ == null) {
          successBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getSuccess(),
                  getParentForChildren(),
                  isClean());
          success_ = null;
        }
        return successBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration failed_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> failedBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public boolean hasFailed() {
        return failedBuilder_ != null || failed_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getFailed() {
        if (failedBuilder_ == null) {
          return failed_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : failed_;
        } else {
          return failedBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public Builder setFailed(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (failedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          failed_ = value;
          onChanged();
        } else {
          failedBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public Builder setFailed(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (failedBuilder_ == null) {
          failed_ = builderForValue.build();
          onChanged();
        } else {
          failedBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public Builder mergeFailed(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (failedBuilder_ == null) {
          if (failed_ != null) {
            failed_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(failed_).mergeFrom(value).buildPartial();
          } else {
            failed_ = value;
          }
          onChanged();
        } else {
          failedBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public Builder clearFailed() {
        if (failedBuilder_ == null) {
          failed_ = null;
          onChanged();
        } else {
          failed_ = null;
          failedBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getFailedBuilder() {
        
        onChanged();
        return getFailedFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getFailedOrBuilder() {
        if (failedBuilder_ != null) {
          return failedBuilder_.getMessageOrBuilder();
        } else {
          return failed_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : failed_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration failed
       *&#64;&#64;
       *&#64;&#64;     Total time required to handle failed Infer requests, not
       *&#64;&#64;     including HTTP or GRPC endpoint handling time.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration failed = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getFailedFieldBuilder() {
        if (failedBuilder_ == null) {
          failedBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getFailed(),
                  getParentForChildren(),
                  isClean());
          failed_ = null;
        }
        return failedBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration compute_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> computeBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public boolean hasCompute() {
        return computeBuilder_ != null || compute_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getCompute() {
        if (computeBuilder_ == null) {
          return compute_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : compute_;
        } else {
          return computeBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public Builder setCompute(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (computeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          compute_ = value;
          onChanged();
        } else {
          computeBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public Builder setCompute(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (computeBuilder_ == null) {
          compute_ = builderForValue.build();
          onChanged();
        } else {
          computeBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public Builder mergeCompute(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (computeBuilder_ == null) {
          if (compute_ != null) {
            compute_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(compute_).mergeFrom(value).buildPartial();
          } else {
            compute_ = value;
          }
          onChanged();
        } else {
          computeBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public Builder clearCompute() {
        if (computeBuilder_ == null) {
          compute_ = null;
          onChanged();
        } else {
          compute_ = null;
          computeBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getComputeBuilder() {
        
        onChanged();
        return getComputeFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getComputeOrBuilder() {
        if (computeBuilder_ != null) {
          return computeBuilder_.getMessageOrBuilder();
        } else {
          return compute_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : compute_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration compute
       *&#64;&#64;
       *&#64;&#64;     Time required to run inferencing for an inference request;
       *&#64;&#64;     including time copying input tensors to GPU memory, time
       *&#64;&#64;     executing the model, and time copying output tensors from GPU
       *&#64;&#64;     memory.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration compute = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getComputeFieldBuilder() {
        if (computeBuilder_ == null) {
          computeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getCompute(),
                  getParentForChildren(),
                  isClean());
          compute_ = null;
        }
        return computeBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatDuration queue_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> queueBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public boolean hasQueue() {
        return queueBuilder_ != null || queue_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration getQueue() {
        if (queueBuilder_ == null) {
          return queue_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : queue_;
        } else {
          return queueBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public Builder setQueue(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (queueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          queue_ = value;
          onChanged();
        } else {
          queueBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public Builder setQueue(
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder builderForValue) {
        if (queueBuilder_ == null) {
          queue_ = builderForValue.build();
          onChanged();
        } else {
          queueBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public Builder mergeQueue(nvidia.inferenceserver.ServerStatusOuterClass.StatDuration value) {
        if (queueBuilder_ == null) {
          if (queue_ != null) {
            queue_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.newBuilder(queue_).mergeFrom(value).buildPartial();
          } else {
            queue_ = value;
          }
          onChanged();
        } else {
          queueBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public Builder clearQueue() {
        if (queueBuilder_ == null) {
          queue_ = null;
          onChanged();
        } else {
          queue_ = null;
          queueBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder getQueueBuilder() {
        
        onChanged();
        return getQueueFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder getQueueOrBuilder() {
        if (queueBuilder_ != null) {
          return queueBuilder_.getMessageOrBuilder();
        } else {
          return queue_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.getDefaultInstance() : queue_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatDuration queue
       *&#64;&#64;
       *&#64;&#64;     Time an inference request waits in scheduling queue for an
       *&#64;&#64;     available model instance.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatDuration queue = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder> 
          getQueueFieldBuilder() {
        if (queueBuilder_ == null) {
          queueBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatDuration, nvidia.inferenceserver.ServerStatusOuterClass.StatDuration.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatDurationOrBuilder>(
                  getQueue(),
                  getParentForChildren(),
                  isClean());
          queue_ = null;
        }
        return queueBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.InferRequestStats)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestStats)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<InferRequestStats>
        PARSER = new com.google.protobuf.AbstractParser<InferRequestStats>() {
      @java.lang.Override
      public InferRequestStats parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new InferRequestStats(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<InferRequestStats> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<InferRequestStats> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelReadyStateReasonOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelReadyStateReason)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string message
     *&#64;&#64;
     *&#64;&#64;     The message that explains the cause of being in the current readiness
     *&#64;&#64;     state.
     *&#64;&#64;
     * </pre>
     *
     * <code>string message = 1;</code>
     */
    java.lang.String getMessage();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string message
     *&#64;&#64;
     *&#64;&#64;     The message that explains the cause of being in the current readiness
     *&#64;&#64;     state.
     *&#64;&#64;
     * </pre>
     *
     * <code>string message = 1;</code>
     */
    com.google.protobuf.ByteString
        getMessageBytes();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:enum:: ModelReadyStateReason
   *&#64;&#64;
   *&#64;&#64;   Detail associated with a model's readiness status.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ModelReadyStateReason}
   */
  public  static final class ModelReadyStateReason extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelReadyStateReason)
      ModelReadyStateReasonOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModelReadyStateReason.newBuilder() to construct.
    private ModelReadyStateReason(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelReadyStateReason() {
      message_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModelReadyStateReason(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              message_ = s;
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelReadyStateReason_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder.class);
    }

    public static final int MESSAGE_FIELD_NUMBER = 1;
    private volatile java.lang.Object message_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string message
     *&#64;&#64;
     *&#64;&#64;     The message that explains the cause of being in the current readiness
     *&#64;&#64;     state.
     *&#64;&#64;
     * </pre>
     *
     * <code>string message = 1;</code>
     */
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        message_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string message
     *&#64;&#64;
     *&#64;&#64;     The message that explains the cause of being in the current readiness
     *&#64;&#64;     state.
     *&#64;&#64;
     * </pre>
     *
     * <code>string message = 1;</code>
     */
    public com.google.protobuf.ByteString
        getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getMessageBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, message_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getMessageBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, message_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason) obj;

      boolean result = true;
      result = result && getMessage()
          .equals(other.getMessage());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
      hash = (53 * hash) + getMessage().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:enum:: ModelReadyStateReason
     *&#64;&#64;
     *&#64;&#64;   Detail associated with a model's readiness status.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelReadyStateReason}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelReadyStateReason)
        nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelReadyStateReason_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        message_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason(this);
        result.message_ = message_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.getDefaultInstance()) return this;
        if (!other.getMessage().isEmpty()) {
          message_ = other.message_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object message_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string message
       *&#64;&#64;
       *&#64;&#64;     The message that explains the cause of being in the current readiness
       *&#64;&#64;     state.
       *&#64;&#64;
       * </pre>
       *
       * <code>string message = 1;</code>
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          message_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string message
       *&#64;&#64;
       *&#64;&#64;     The message that explains the cause of being in the current readiness
       *&#64;&#64;     state.
       *&#64;&#64;
       * </pre>
       *
       * <code>string message = 1;</code>
       */
      public com.google.protobuf.ByteString
          getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string message
       *&#64;&#64;
       *&#64;&#64;     The message that explains the cause of being in the current readiness
       *&#64;&#64;     state.
       *&#64;&#64;
       * </pre>
       *
       * <code>string message = 1;</code>
       */
      public Builder setMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        message_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string message
       *&#64;&#64;
       *&#64;&#64;     The message that explains the cause of being in the current readiness
       *&#64;&#64;     state.
       *&#64;&#64;
       * </pre>
       *
       * <code>string message = 1;</code>
       */
      public Builder clearMessage() {
        
        message_ = getDefaultInstance().getMessage();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string message
       *&#64;&#64;
       *&#64;&#64;     The message that explains the cause of being in the current readiness
       *&#64;&#64;     state.
       *&#64;&#64;
       * </pre>
       *
       * <code>string message = 1;</code>
       */
      public Builder setMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        message_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelReadyStateReason)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelReadyStateReason)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelReadyStateReason>
        PARSER = new com.google.protobuf.AbstractParser<ModelReadyStateReason>() {
      @java.lang.Override
      public ModelReadyStateReason parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModelReadyStateReason(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelReadyStateReason> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModelReadyStateReason> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelVersionStatusOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelVersionStatus)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
     */
    int getReadyStateValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState getReadyState();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    boolean hasReadyStateReason();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getReadyStateReason();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder getReadyStateReasonOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */
    int getInferStatsCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */
    boolean containsInferStats(
        int key);
    /**
     * Use {@link #getInferStatsMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
    getInferStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */
    java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
    getInferStatsMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrDefault(
        int key,
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrThrow(
        int key);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 model_execution_count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of model executions performed for the
     *&#64;&#64;     model. A single model execution performs inferencing for
     *&#64;&#64;     the entire request batch and can perform inferencing for multiple
     *&#64;&#64;     requests if dynamic batching is enabled.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 model_execution_count = 3;</code>
     */
    long getModelExecutionCount();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 model_inference_count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of model inferences performed for the
     *&#64;&#64;     model. Each inference in a batched request is counted as
     *&#64;&#64;     an individual inference.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 model_inference_count = 4;</code>
     */
    long getModelInferenceCount();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 last_inference_timestamp_milliseconds
     *&#64;&#64;
     *&#64;&#64;     The timestamp of the last inference request made for this model,
     *&#64;&#64;     given as milliseconds since the epoch.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 last_inference_timestamp_milliseconds = 6;</code>
     */
    long getLastInferenceTimestampMilliseconds();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelVersionStatus
   *&#64;&#64;
   *&#64;&#64;   Status for a version of a model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ModelVersionStatus}
   */
  public  static final class ModelVersionStatus extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelVersionStatus)
      ModelVersionStatusOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModelVersionStatus.newBuilder() to construct.
    private ModelVersionStatus(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelVersionStatus() {
      readyState_ = 0;
      modelExecutionCount_ = 0L;
      modelInferenceCount_ = 0L;
      lastInferenceTimestampMilliseconds_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModelVersionStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              readyState_ = rawValue;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                inferStats_ = com.google.protobuf.MapField.newMapField(
                    InferStatsDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000004;
              }
              com.google.protobuf.MapEntry<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
              inferStats__ = input.readMessage(
                  InferStatsDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              inferStats_.getMutableMap().put(
                  inferStats__.getKey(), inferStats__.getValue());
              break;
            }
            case 24: {

              modelExecutionCount_ = input.readUInt64();
              break;
            }
            case 32: {

              modelInferenceCount_ = input.readUInt64();
              break;
            }
            case 42: {
              nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder subBuilder = null;
              if (readyStateReason_ != null) {
                subBuilder = readyStateReason_.toBuilder();
              }
              readyStateReason_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(readyStateReason_);
                readyStateReason_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {

              lastInferenceTimestampMilliseconds_ = input.readUInt64();
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 2:
          return internalGetInferStats();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.Builder.class);
    }

    private int bitField0_;
    public static final int READY_STATE_FIELD_NUMBER = 1;
    private int readyState_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
     */
    public int getReadyStateValue() {
      return readyState_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState getReadyState() {
      @SuppressWarnings("deprecation")
      nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState result = nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.valueOf(readyState_);
      return result == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.UNRECOGNIZED : result;
    }

    public static final int READY_STATE_REASON_FIELD_NUMBER = 5;
    private nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason readyStateReason_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    public boolean hasReadyStateReason() {
      return readyStateReason_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getReadyStateReason() {
      return readyStateReason_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.getDefaultInstance() : readyStateReason_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
     *&#64;&#64;
     *&#64;&#64;     Supplemental information regarding the current readiness state.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder getReadyStateReasonOrBuilder() {
      return getReadyStateReason();
    }

    public static final int INFER_STATS_FIELD_NUMBER = 2;
    private static final class InferStatsDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>newDefaultInstance(
                  nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.UINT32,
                  0,
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> inferStats_;
    private com.google.protobuf.MapField<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
    internalGetInferStats() {
      if (inferStats_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            InferStatsDefaultEntryHolder.defaultEntry);
      }
      return inferStats_;
    }

    public int getInferStatsCount() {
      return internalGetInferStats().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    public boolean containsInferStats(
        int key) {
      
      return internalGetInferStats().getMap().containsKey(key);
    }
    /**
     * Use {@link #getInferStatsMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> getInferStats() {
      return getInferStatsMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    public java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> getInferStatsMap() {
      return internalGetInferStats().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrDefault(
        int key,
        nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats defaultValue) {
      
      java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> map =
          internalGetInferStats().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
     *&#64;&#64;
     *&#64;&#64;     Inference statistics for the model, as a map from batch size
     *&#64;&#64;     to the statistics. A batch size will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that batch size.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrThrow(
        int key) {
      
      java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> map =
          internalGetInferStats().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int MODEL_EXECUTION_COUNT_FIELD_NUMBER = 3;
    private long modelExecutionCount_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 model_execution_count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of model executions performed for the
     *&#64;&#64;     model. A single model execution performs inferencing for
     *&#64;&#64;     the entire request batch and can perform inferencing for multiple
     *&#64;&#64;     requests if dynamic batching is enabled.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 model_execution_count = 3;</code>
     */
    public long getModelExecutionCount() {
      return modelExecutionCount_;
    }

    public static final int MODEL_INFERENCE_COUNT_FIELD_NUMBER = 4;
    private long modelInferenceCount_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 model_inference_count
     *&#64;&#64;
     *&#64;&#64;     Cumulative number of model inferences performed for the
     *&#64;&#64;     model. Each inference in a batched request is counted as
     *&#64;&#64;     an individual inference.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 model_inference_count = 4;</code>
     */
    public long getModelInferenceCount() {
      return modelInferenceCount_;
    }

    public static final int LAST_INFERENCE_TIMESTAMP_MILLISECONDS_FIELD_NUMBER = 6;
    private long lastInferenceTimestampMilliseconds_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 last_inference_timestamp_milliseconds
     *&#64;&#64;
     *&#64;&#64;     The timestamp of the last inference request made for this model,
     *&#64;&#64;     given as milliseconds since the epoch.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 last_inference_timestamp_milliseconds = 6;</code>
     */
    public long getLastInferenceTimestampMilliseconds() {
      return lastInferenceTimestampMilliseconds_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (readyState_ != nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.MODEL_UNKNOWN.getNumber()) {
        output.writeEnum(1, readyState_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeIntegerMapTo(
          output,
          internalGetInferStats(),
          InferStatsDefaultEntryHolder.defaultEntry,
          2);
      if (modelExecutionCount_ != 0L) {
        output.writeUInt64(3, modelExecutionCount_);
      }
      if (modelInferenceCount_ != 0L) {
        output.writeUInt64(4, modelInferenceCount_);
      }
      if (readyStateReason_ != null) {
        output.writeMessage(5, getReadyStateReason());
      }
      if (lastInferenceTimestampMilliseconds_ != 0L) {
        output.writeUInt64(6, lastInferenceTimestampMilliseconds_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (readyState_ != nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.MODEL_UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, readyState_);
      }
      for (java.util.Map.Entry<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> entry
           : internalGetInferStats().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
        inferStats__ = InferStatsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, inferStats__);
      }
      if (modelExecutionCount_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, modelExecutionCount_);
      }
      if (modelInferenceCount_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, modelInferenceCount_);
      }
      if (readyStateReason_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getReadyStateReason());
      }
      if (lastInferenceTimestampMilliseconds_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(6, lastInferenceTimestampMilliseconds_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus) obj;

      boolean result = true;
      result = result && readyState_ == other.readyState_;
      result = result && (hasReadyStateReason() == other.hasReadyStateReason());
      if (hasReadyStateReason()) {
        result = result && getReadyStateReason()
            .equals(other.getReadyStateReason());
      }
      result = result && internalGetInferStats().equals(
          other.internalGetInferStats());
      result = result && (getModelExecutionCount()
          == other.getModelExecutionCount());
      result = result && (getModelInferenceCount()
          == other.getModelInferenceCount());
      result = result && (getLastInferenceTimestampMilliseconds()
          == other.getLastInferenceTimestampMilliseconds());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + READY_STATE_FIELD_NUMBER;
      hash = (53 * hash) + readyState_;
      if (hasReadyStateReason()) {
        hash = (37 * hash) + READY_STATE_REASON_FIELD_NUMBER;
        hash = (53 * hash) + getReadyStateReason().hashCode();
      }
      if (!internalGetInferStats().getMap().isEmpty()) {
        hash = (37 * hash) + INFER_STATS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetInferStats().hashCode();
      }
      hash = (37 * hash) + MODEL_EXECUTION_COUNT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getModelExecutionCount());
      hash = (37 * hash) + MODEL_INFERENCE_COUNT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getModelInferenceCount());
      hash = (37 * hash) + LAST_INFERENCE_TIMESTAMP_MILLISECONDS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getLastInferenceTimestampMilliseconds());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelVersionStatus
     *&#64;&#64;
     *&#64;&#64;   Status for a version of a model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelVersionStatus}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelVersionStatus)
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetInferStats();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetMutableInferStats();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        readyState_ = 0;

        if (readyStateReasonBuilder_ == null) {
          readyStateReason_ = null;
        } else {
          readyStateReason_ = null;
          readyStateReasonBuilder_ = null;
        }
        internalGetMutableInferStats().clear();
        modelExecutionCount_ = 0L;

        modelInferenceCount_ = 0L;

        lastInferenceTimestampMilliseconds_ = 0L;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.readyState_ = readyState_;
        if (readyStateReasonBuilder_ == null) {
          result.readyStateReason_ = readyStateReason_;
        } else {
          result.readyStateReason_ = readyStateReasonBuilder_.build();
        }
        result.inferStats_ = internalGetInferStats();
        result.inferStats_.makeImmutable();
        result.modelExecutionCount_ = modelExecutionCount_;
        result.modelInferenceCount_ = modelInferenceCount_;
        result.lastInferenceTimestampMilliseconds_ = lastInferenceTimestampMilliseconds_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.getDefaultInstance()) return this;
        if (other.readyState_ != 0) {
          setReadyStateValue(other.getReadyStateValue());
        }
        if (other.hasReadyStateReason()) {
          mergeReadyStateReason(other.getReadyStateReason());
        }
        internalGetMutableInferStats().mergeFrom(
            other.internalGetInferStats());
        if (other.getModelExecutionCount() != 0L) {
          setModelExecutionCount(other.getModelExecutionCount());
        }
        if (other.getModelInferenceCount() != 0L) {
          setModelInferenceCount(other.getModelInferenceCount());
        }
        if (other.getLastInferenceTimestampMilliseconds() != 0L) {
          setLastInferenceTimestampMilliseconds(other.getLastInferenceTimestampMilliseconds());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int readyState_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
       */
      public int getReadyStateValue() {
        return readyState_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
       */
      public Builder setReadyStateValue(int value) {
        readyState_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState getReadyState() {
        @SuppressWarnings("deprecation")
        nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState result = nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.valueOf(readyState_);
        return result == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
       */
      public Builder setReadyState(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        readyState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyState ready_state = 1;</code>
       */
      public Builder clearReadyState() {
        
        readyState_ = 0;
        onChanged();
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason readyStateReason_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder> readyStateReasonBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public boolean hasReadyStateReason() {
        return readyStateReasonBuilder_ != null || readyStateReason_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason getReadyStateReason() {
        if (readyStateReasonBuilder_ == null) {
          return readyStateReason_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.getDefaultInstance() : readyStateReason_;
        } else {
          return readyStateReasonBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public Builder setReadyStateReason(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason value) {
        if (readyStateReasonBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          readyStateReason_ = value;
          onChanged();
        } else {
          readyStateReasonBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public Builder setReadyStateReason(
          nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder builderForValue) {
        if (readyStateReasonBuilder_ == null) {
          readyStateReason_ = builderForValue.build();
          onChanged();
        } else {
          readyStateReasonBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public Builder mergeReadyStateReason(nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason value) {
        if (readyStateReasonBuilder_ == null) {
          if (readyStateReason_ != null) {
            readyStateReason_ =
              nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.newBuilder(readyStateReason_).mergeFrom(value).buildPartial();
          } else {
            readyStateReason_ = value;
          }
          onChanged();
        } else {
          readyStateReasonBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public Builder clearReadyStateReason() {
        if (readyStateReasonBuilder_ == null) {
          readyStateReason_ = null;
          onChanged();
        } else {
          readyStateReason_ = null;
          readyStateReasonBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder getReadyStateReasonBuilder() {
        
        onChanged();
        return getReadyStateReasonFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder getReadyStateReasonOrBuilder() {
        if (readyStateReasonBuilder_ != null) {
          return readyStateReasonBuilder_.getMessageOrBuilder();
        } else {
          return readyStateReason_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.getDefaultInstance() : readyStateReason_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelReadyStateReason ready_state_reason
       *&#64;&#64;
       *&#64;&#64;     Supplemental information regarding the current readiness state.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelReadyStateReason ready_state_reason = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder> 
          getReadyStateReasonFieldBuilder() {
        if (readyStateReasonBuilder_ == null) {
          readyStateReasonBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReason.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelReadyStateReasonOrBuilder>(
                  getReadyStateReason(),
                  getParentForChildren(),
                  isClean());
          readyStateReason_ = null;
        }
        return readyStateReasonBuilder_;
      }

      private com.google.protobuf.MapField<
          java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> inferStats_;
      private com.google.protobuf.MapField<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
      internalGetInferStats() {
        if (inferStats_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              InferStatsDefaultEntryHolder.defaultEntry);
        }
        return inferStats_;
      }
      private com.google.protobuf.MapField<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
      internalGetMutableInferStats() {
        onChanged();;
        if (inferStats_ == null) {
          inferStats_ = com.google.protobuf.MapField.newMapField(
              InferStatsDefaultEntryHolder.defaultEntry);
        }
        if (!inferStats_.isMutable()) {
          inferStats_ = inferStats_.copy();
        }
        return inferStats_;
      }

      public int getInferStatsCount() {
        return internalGetInferStats().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public boolean containsInferStats(
          int key) {
        
        return internalGetInferStats().getMap().containsKey(key);
      }
      /**
       * Use {@link #getInferStatsMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> getInferStats() {
        return getInferStatsMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> getInferStatsMap() {
        return internalGetInferStats().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrDefault(
          int key,
          nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats defaultValue) {
        
        java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> map =
            internalGetInferStats().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats getInferStatsOrThrow(
          int key) {
        
        java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> map =
            internalGetInferStats().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearInferStats() {
        internalGetMutableInferStats().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public Builder removeInferStats(
          int key) {
        
        internalGetMutableInferStats().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats>
      getMutableInferStats() {
        return internalGetMutableInferStats().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */
      public Builder putInferStats(
          int key,
          nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats value) {
        
        if (value == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableInferStats().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, InferRequestStats&gt; infer_stats
       *&#64;&#64;
       *&#64;&#64;     Inference statistics for the model, as a map from batch size
       *&#64;&#64;     to the statistics. A batch size will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that batch size.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .nvidia.inferenceserver.InferRequestStats&gt; infer_stats = 2;</code>
       */

      public Builder putAllInferStats(
          java.util.Map<java.lang.Integer, nvidia.inferenceserver.ServerStatusOuterClass.InferRequestStats> values) {
        internalGetMutableInferStats().getMutableMap()
            .putAll(values);
        return this;
      }

      private long modelExecutionCount_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_execution_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model executions performed for the
       *&#64;&#64;     model. A single model execution performs inferencing for
       *&#64;&#64;     the entire request batch and can perform inferencing for multiple
       *&#64;&#64;     requests if dynamic batching is enabled.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_execution_count = 3;</code>
       */
      public long getModelExecutionCount() {
        return modelExecutionCount_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_execution_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model executions performed for the
       *&#64;&#64;     model. A single model execution performs inferencing for
       *&#64;&#64;     the entire request batch and can perform inferencing for multiple
       *&#64;&#64;     requests if dynamic batching is enabled.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_execution_count = 3;</code>
       */
      public Builder setModelExecutionCount(long value) {
        
        modelExecutionCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_execution_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model executions performed for the
       *&#64;&#64;     model. A single model execution performs inferencing for
       *&#64;&#64;     the entire request batch and can perform inferencing for multiple
       *&#64;&#64;     requests if dynamic batching is enabled.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_execution_count = 3;</code>
       */
      public Builder clearModelExecutionCount() {
        
        modelExecutionCount_ = 0L;
        onChanged();
        return this;
      }

      private long modelInferenceCount_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_inference_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model inferences performed for the
       *&#64;&#64;     model. Each inference in a batched request is counted as
       *&#64;&#64;     an individual inference.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_inference_count = 4;</code>
       */
      public long getModelInferenceCount() {
        return modelInferenceCount_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_inference_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model inferences performed for the
       *&#64;&#64;     model. Each inference in a batched request is counted as
       *&#64;&#64;     an individual inference.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_inference_count = 4;</code>
       */
      public Builder setModelInferenceCount(long value) {
        
        modelInferenceCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 model_inference_count
       *&#64;&#64;
       *&#64;&#64;     Cumulative number of model inferences performed for the
       *&#64;&#64;     model. Each inference in a batched request is counted as
       *&#64;&#64;     an individual inference.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 model_inference_count = 4;</code>
       */
      public Builder clearModelInferenceCount() {
        
        modelInferenceCount_ = 0L;
        onChanged();
        return this;
      }

      private long lastInferenceTimestampMilliseconds_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 last_inference_timestamp_milliseconds
       *&#64;&#64;
       *&#64;&#64;     The timestamp of the last inference request made for this model,
       *&#64;&#64;     given as milliseconds since the epoch.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 last_inference_timestamp_milliseconds = 6;</code>
       */
      public long getLastInferenceTimestampMilliseconds() {
        return lastInferenceTimestampMilliseconds_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 last_inference_timestamp_milliseconds
       *&#64;&#64;
       *&#64;&#64;     The timestamp of the last inference request made for this model,
       *&#64;&#64;     given as milliseconds since the epoch.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 last_inference_timestamp_milliseconds = 6;</code>
       */
      public Builder setLastInferenceTimestampMilliseconds(long value) {
        
        lastInferenceTimestampMilliseconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 last_inference_timestamp_milliseconds
       *&#64;&#64;
       *&#64;&#64;     The timestamp of the last inference request made for this model,
       *&#64;&#64;     given as milliseconds since the epoch.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 last_inference_timestamp_milliseconds = 6;</code>
       */
      public Builder clearLastInferenceTimestampMilliseconds() {
        
        lastInferenceTimestampMilliseconds_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelVersionStatus)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelVersionStatus)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelVersionStatus>
        PARSER = new com.google.protobuf.AbstractParser<ModelVersionStatus>() {
      @java.lang.Override
      public ModelVersionStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModelVersionStatus(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelVersionStatus> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModelVersionStatus> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelStatusOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelStatus)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    boolean hasConfig();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig getConfig();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */
    int getVersionStatusCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */
    boolean containsVersionStatus(
        long key);
    /**
     * Use {@link #getVersionStatusMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
    getVersionStatus();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */
    java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
    getVersionStatusMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrDefault(
        long key,
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrThrow(
        long key);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelStatus
   *&#64;&#64;
   *&#64;&#64;   Status for a model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ModelStatus}
   */
  public  static final class ModelStatus extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelStatus)
      ModelStatusOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModelStatus.newBuilder() to construct.
    private ModelStatus(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelStatus() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModelStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder subBuilder = null;
              if (config_ != null) {
                subBuilder = config_.toBuilder();
              }
              config_ = input.readMessage(nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(config_);
                config_ = subBuilder.buildPartial();
              }

              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                versionStatus_ = com.google.protobuf.MapField.newMapField(
                    VersionStatusDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000002;
              }
              com.google.protobuf.MapEntry<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
              versionStatus__ = input.readMessage(
                  VersionStatusDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              versionStatus_.getMutableMap().put(
                  versionStatus__.getKey(), versionStatus__.getValue());
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 2:
          return internalGetVersionStatus();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.Builder.class);
    }

    private int bitField0_;
    public static final int CONFIG_FIELD_NUMBER = 1;
    private nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig config_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    public nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig getConfig() {
      return config_ == null ? nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelConfig config
     *&#64;&#64;
     *&#64;&#64;     The configuration for the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
     */
    public nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder getConfigOrBuilder() {
      return getConfig();
    }

    public static final int VERSION_STATUS_FIELD_NUMBER = 2;
    private static final class VersionStatusDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>newDefaultInstance(
                  nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.INT64,
                  0L,
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> versionStatus_;
    private com.google.protobuf.MapField<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
    internalGetVersionStatus() {
      if (versionStatus_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            VersionStatusDefaultEntryHolder.defaultEntry);
      }
      return versionStatus_;
    }

    public int getVersionStatusCount() {
      return internalGetVersionStatus().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    public boolean containsVersionStatus(
        long key) {
      
      return internalGetVersionStatus().getMap().containsKey(key);
    }
    /**
     * Use {@link #getVersionStatusMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> getVersionStatus() {
      return getVersionStatusMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    public java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> getVersionStatusMap() {
      return internalGetVersionStatus().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrDefault(
        long key,
        nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus defaultValue) {
      
      java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> map =
          internalGetVersionStatus().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
     *&#64;&#64;
     *&#64;&#64;     Duration statistics for each version of the model, as a map
     *&#64;&#64;     from version to the status. A version will not occur in the map
     *&#64;&#64;     unless there has been at least one inference request of
     *&#64;&#64;     that model version. A version of -1 indicates the status is
     *&#64;&#64;     for requests for which the version could not be determined.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrThrow(
        long key) {
      
      java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> map =
          internalGetVersionStatus().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (config_ != null) {
        output.writeMessage(1, getConfig());
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeLongMapTo(
          output,
          internalGetVersionStatus(),
          VersionStatusDefaultEntryHolder.defaultEntry,
          2);
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getConfig());
      }
      for (java.util.Map.Entry<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> entry
           : internalGetVersionStatus().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
        versionStatus__ = VersionStatusDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, versionStatus__);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus) obj;

      boolean result = true;
      result = result && (hasConfig() == other.hasConfig());
      if (hasConfig()) {
        result = result && getConfig()
            .equals(other.getConfig());
      }
      result = result && internalGetVersionStatus().equals(
          other.internalGetVersionStatus());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      if (!internalGetVersionStatus().getMap().isEmpty()) {
        hash = (37 * hash) + VERSION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetVersionStatus().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelStatus
     *&#64;&#64;
     *&#64;&#64;   Status for a model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelStatus}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelStatus)
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetVersionStatus();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetMutableVersionStatus();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (configBuilder_ == null) {
          config_ = null;
        } else {
          config_ = null;
          configBuilder_ = null;
        }
        internalGetMutableVersionStatus().clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelStatus_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (configBuilder_ == null) {
          result.config_ = config_;
        } else {
          result.config_ = configBuilder_.build();
        }
        result.versionStatus_ = internalGetVersionStatus();
        result.versionStatus_.makeImmutable();
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.getDefaultInstance()) return this;
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        internalGetMutableVersionStatus().mergeFrom(
            other.internalGetVersionStatus());
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig config_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder> configBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public boolean hasConfig() {
        return configBuilder_ != null || config_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public Builder setConfig(nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
          onChanged();
        } else {
          configBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public Builder setConfig(
          nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
          onChanged();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public Builder mergeConfig(nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig value) {
        if (configBuilder_ == null) {
          if (config_ != null) {
            config_ =
              nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.newBuilder(config_).mergeFrom(value).buildPartial();
          } else {
            config_ = value;
          }
          onChanged();
        } else {
          configBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public Builder clearConfig() {
        if (configBuilder_ == null) {
          config_ = null;
          onChanged();
        } else {
          config_ = null;
          configBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder getConfigBuilder() {
        
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      public nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelConfig config
       *&#64;&#64;
       *&#64;&#64;     The configuration for the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelConfig config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder> 
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfig.Builder, nvidia.inferenceserver.ModelConfigOuterClass.ModelConfigOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private com.google.protobuf.MapField<
          java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> versionStatus_;
      private com.google.protobuf.MapField<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
      internalGetVersionStatus() {
        if (versionStatus_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              VersionStatusDefaultEntryHolder.defaultEntry);
        }
        return versionStatus_;
      }
      private com.google.protobuf.MapField<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
      internalGetMutableVersionStatus() {
        onChanged();;
        if (versionStatus_ == null) {
          versionStatus_ = com.google.protobuf.MapField.newMapField(
              VersionStatusDefaultEntryHolder.defaultEntry);
        }
        if (!versionStatus_.isMutable()) {
          versionStatus_ = versionStatus_.copy();
        }
        return versionStatus_;
      }

      public int getVersionStatusCount() {
        return internalGetVersionStatus().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public boolean containsVersionStatus(
          long key) {
        
        return internalGetVersionStatus().getMap().containsKey(key);
      }
      /**
       * Use {@link #getVersionStatusMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> getVersionStatus() {
        return getVersionStatusMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> getVersionStatusMap() {
        return internalGetVersionStatus().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrDefault(
          long key,
          nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus defaultValue) {
        
        java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> map =
            internalGetVersionStatus().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus getVersionStatusOrThrow(
          long key) {
        
        java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> map =
            internalGetVersionStatus().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearVersionStatus() {
        internalGetMutableVersionStatus().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public Builder removeVersionStatus(
          long key) {
        
        internalGetMutableVersionStatus().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus>
      getMutableVersionStatus() {
        return internalGetMutableVersionStatus().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */
      public Builder putVersionStatus(
          long key,
          nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus value) {
        
        if (value == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableVersionStatus().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;int64, ModelVersionStatus&gt; version_status
       *&#64;&#64;
       *&#64;&#64;     Duration statistics for each version of the model, as a map
       *&#64;&#64;     from version to the status. A version will not occur in the map
       *&#64;&#64;     unless there has been at least one inference request of
       *&#64;&#64;     that model version. A version of -1 indicates the status is
       *&#64;&#64;     for requests for which the version could not be determined.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;int64, .nvidia.inferenceserver.ModelVersionStatus&gt; version_status = 2;</code>
       */

      public Builder putAllVersionStatus(
          java.util.Map<java.lang.Long, nvidia.inferenceserver.ServerStatusOuterClass.ModelVersionStatus> values) {
        internalGetMutableVersionStatus().getMutableMap()
            .putAll(values);
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelStatus)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelStatus)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelStatus>
        PARSER = new com.google.protobuf.AbstractParser<ModelStatus>() {
      @java.lang.Override
      public ModelStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModelStatus(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelStatus> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModelStatus> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SharedMemoryRegionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.SharedMemoryRegion)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name for this shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name for this shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    boolean hasSystemSharedMemory();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getSystemSharedMemory();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder getSystemSharedMemoryOrBuilder();

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    boolean hasCudaSharedMemory();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getCudaSharedMemory();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder getCudaSharedMemoryOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 byte_size
     *&#64;&#64;
     *&#64;&#64;     Size of the shared memory block, in bytes.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 byte_size = 5;</code>
     */
    long getByteSize();

    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SharedMemoryTypesCase getSharedMemoryTypesCase();
  }
  /**
   * <pre>
   *&#64;&#64;.. cpp:var:: message SharedMemoryRegion
   *&#64;&#64;
   *&#64;&#64;   The meta-data for the shared memory region registered in the inference
   *&#64;&#64;   server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion}
   */
  public  static final class SharedMemoryRegion extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.SharedMemoryRegion)
      SharedMemoryRegionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SharedMemoryRegion.newBuilder() to construct.
    private SharedMemoryRegion(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SharedMemoryRegion() {
      name_ = "";
      byteSize_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SharedMemoryRegion(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder subBuilder = null;
              if (sharedMemoryTypesCase_ == 2) {
                subBuilder = ((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_).toBuilder();
              }
              sharedMemoryTypes_ =
                  input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_);
                sharedMemoryTypes_ = subBuilder.buildPartial();
              }
              sharedMemoryTypesCase_ = 2;
              break;
            }
            case 26: {
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder subBuilder = null;
              if (sharedMemoryTypesCase_ == 3) {
                subBuilder = ((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_).toBuilder();
              }
              sharedMemoryTypes_ =
                  input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_);
                sharedMemoryTypes_ = subBuilder.buildPartial();
              }
              sharedMemoryTypesCase_ = 3;
              break;
            }
            case 40: {

              byteSize_ = input.readUInt64();
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder.class);
    }

    public interface SystemSharedMemoryOrBuilder extends
        // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string shared_memory_key
       *&#64;&#64;
       *&#64;&#64;     The name of the shared memory region that holds the input data
       *&#64;&#64;     (or where the output data should be written).
       *&#64;&#64;
       * </pre>
       *
       * <code>string shared_memory_key = 1;</code>
       */
      java.lang.String getSharedMemoryKey();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string shared_memory_key
       *&#64;&#64;
       *&#64;&#64;     The name of the shared memory region that holds the input data
       *&#64;&#64;     (or where the output data should be written).
       *&#64;&#64;
       * </pre>
       *
       * <code>string shared_memory_key = 1;</code>
       */
      com.google.protobuf.ByteString
          getSharedMemoryKeyBytes();

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 offset
       *&#64;&#64;
       *&#64;&#64;     This is the offset of the shared memory block from the start
       *&#64;&#64;     of the shared memory region.
       *&#64;&#64;     start = offset, end = offset + byte_size;
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 offset = 2;</code>
       */
      long getOffset();
    }
    /**
     * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory}
     */
    public  static final class SystemSharedMemory extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory)
        SystemSharedMemoryOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use SystemSharedMemory.newBuilder() to construct.
      private SystemSharedMemory(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private SystemSharedMemory() {
        sharedMemoryKey_ = "";
        offset_ = 0L;
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private SystemSharedMemory(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                java.lang.String s = input.readStringRequireUtf8();

                sharedMemoryKey_ = s;
                break;
              }
              case 16: {

                offset_ = input.readUInt64();
                break;
              }
              default: {
                if (!parseUnknownFieldProto3(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder.class);
      }

      public static final int SHARED_MEMORY_KEY_FIELD_NUMBER = 1;
      private volatile java.lang.Object sharedMemoryKey_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string shared_memory_key
       *&#64;&#64;
       *&#64;&#64;     The name of the shared memory region that holds the input data
       *&#64;&#64;     (or where the output data should be written).
       *&#64;&#64;
       * </pre>
       *
       * <code>string shared_memory_key = 1;</code>
       */
      public java.lang.String getSharedMemoryKey() {
        java.lang.Object ref = sharedMemoryKey_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          sharedMemoryKey_ = s;
          return s;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string shared_memory_key
       *&#64;&#64;
       *&#64;&#64;     The name of the shared memory region that holds the input data
       *&#64;&#64;     (or where the output data should be written).
       *&#64;&#64;
       * </pre>
       *
       * <code>string shared_memory_key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getSharedMemoryKeyBytes() {
        java.lang.Object ref = sharedMemoryKey_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          sharedMemoryKey_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int OFFSET_FIELD_NUMBER = 2;
      private long offset_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 offset
       *&#64;&#64;
       *&#64;&#64;     This is the offset of the shared memory block from the start
       *&#64;&#64;     of the shared memory region.
       *&#64;&#64;     start = offset, end = offset + byte_size;
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 offset = 2;</code>
       */
      public long getOffset() {
        return offset_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!getSharedMemoryKeyBytes().isEmpty()) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, sharedMemoryKey_);
        }
        if (offset_ != 0L) {
          output.writeUInt64(2, offset_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!getSharedMemoryKeyBytes().isEmpty()) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, sharedMemoryKey_);
        }
        if (offset_ != 0L) {
          size += com.google.protobuf.CodedOutputStream
            .computeUInt64Size(2, offset_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory)) {
          return super.equals(obj);
        }
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory other = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) obj;

        boolean result = true;
        result = result && getSharedMemoryKey()
            .equals(other.getSharedMemoryKey());
        result = result && (getOffset()
            == other.getOffset());
        result = result && unknownFields.equals(other.unknownFields);
        return result;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + SHARED_MEMORY_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getSharedMemoryKey().hashCode();
        hash = (37 * hash) + OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getOffset());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory)
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder.class);
        }

        // Construct using nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          sharedMemoryKey_ = "";

          offset_ = 0L;

          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getDefaultInstanceForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory build() {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory buildPartial() {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory result = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory(this);
          result.sharedMemoryKey_ = sharedMemoryKey_;
          result.offset_ = offset_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return (Builder) super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) {
            return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory other) {
          if (other == nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance()) return this;
          if (!other.getSharedMemoryKey().isEmpty()) {
            sharedMemoryKey_ = other.sharedMemoryKey_;
            onChanged();
          }
          if (other.getOffset() != 0L) {
            setOffset(other.getOffset());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private java.lang.Object sharedMemoryKey_ = "";
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string shared_memory_key
         *&#64;&#64;
         *&#64;&#64;     The name of the shared memory region that holds the input data
         *&#64;&#64;     (or where the output data should be written).
         *&#64;&#64;
         * </pre>
         *
         * <code>string shared_memory_key = 1;</code>
         */
        public java.lang.String getSharedMemoryKey() {
          java.lang.Object ref = sharedMemoryKey_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            sharedMemoryKey_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string shared_memory_key
         *&#64;&#64;
         *&#64;&#64;     The name of the shared memory region that holds the input data
         *&#64;&#64;     (or where the output data should be written).
         *&#64;&#64;
         * </pre>
         *
         * <code>string shared_memory_key = 1;</code>
         */
        public com.google.protobuf.ByteString
            getSharedMemoryKeyBytes() {
          java.lang.Object ref = sharedMemoryKey_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            sharedMemoryKey_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string shared_memory_key
         *&#64;&#64;
         *&#64;&#64;     The name of the shared memory region that holds the input data
         *&#64;&#64;     (or where the output data should be written).
         *&#64;&#64;
         * </pre>
         *
         * <code>string shared_memory_key = 1;</code>
         */
        public Builder setSharedMemoryKey(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  
          sharedMemoryKey_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string shared_memory_key
         *&#64;&#64;
         *&#64;&#64;     The name of the shared memory region that holds the input data
         *&#64;&#64;     (or where the output data should be written).
         *&#64;&#64;
         * </pre>
         *
         * <code>string shared_memory_key = 1;</code>
         */
        public Builder clearSharedMemoryKey() {
          
          sharedMemoryKey_ = getDefaultInstance().getSharedMemoryKey();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string shared_memory_key
         *&#64;&#64;
         *&#64;&#64;     The name of the shared memory region that holds the input data
         *&#64;&#64;     (or where the output data should be written).
         *&#64;&#64;
         * </pre>
         *
         * <code>string shared_memory_key = 1;</code>
         */
        public Builder setSharedMemoryKeyBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
          
          sharedMemoryKey_ = value;
          onChanged();
          return this;
        }

        private long offset_ ;
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: uint64 offset
         *&#64;&#64;
         *&#64;&#64;     This is the offset of the shared memory block from the start
         *&#64;&#64;     of the shared memory region.
         *&#64;&#64;     start = offset, end = offset + byte_size;
         *&#64;&#64;
         * </pre>
         *
         * <code>uint64 offset = 2;</code>
         */
        public long getOffset() {
          return offset_;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: uint64 offset
         *&#64;&#64;
         *&#64;&#64;     This is the offset of the shared memory block from the start
         *&#64;&#64;     of the shared memory region.
         *&#64;&#64;     start = offset, end = offset + byte_size;
         *&#64;&#64;
         * </pre>
         *
         * <code>uint64 offset = 2;</code>
         */
        public Builder setOffset(long value) {
          
          offset_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: uint64 offset
         *&#64;&#64;
         *&#64;&#64;     This is the offset of the shared memory block from the start
         *&#64;&#64;     of the shared memory region.
         *&#64;&#64;     start = offset, end = offset + byte_size;
         *&#64;&#64;
         * </pre>
         *
         * <code>uint64 offset = 2;</code>
         */
        public Builder clearOffset() {
          
          offset_ = 0L;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFieldsProto3(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory)
      }

      // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory)
      private static final nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory();
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<SystemSharedMemory>
          PARSER = new com.google.protobuf.AbstractParser<SystemSharedMemory>() {
        @java.lang.Override
        public SystemSharedMemory parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new SystemSharedMemory(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<SystemSharedMemory> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<SystemSharedMemory> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface CudaSharedMemoryOrBuilder extends
        // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 device_id
       *&#64;&#64;
       *&#64;&#64;     The GPU device ID on which the cudaIPC handle was created.
       *&#64;&#64;
       * </pre>
       *
       * <code>int64 device_id = 1;</code>
       */
      long getDeviceId();
    }
    /**
     * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory}
     */
    public  static final class CudaSharedMemory extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory)
        CudaSharedMemoryOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use CudaSharedMemory.newBuilder() to construct.
      private CudaSharedMemory(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private CudaSharedMemory() {
        deviceId_ = 0L;
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private CudaSharedMemory(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {

                deviceId_ = input.readInt64();
                break;
              }
              default: {
                if (!parseUnknownFieldProto3(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder.class);
      }

      public static final int DEVICE_ID_FIELD_NUMBER = 1;
      private long deviceId_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 device_id
       *&#64;&#64;
       *&#64;&#64;     The GPU device ID on which the cudaIPC handle was created.
       *&#64;&#64;
       * </pre>
       *
       * <code>int64 device_id = 1;</code>
       */
      public long getDeviceId() {
        return deviceId_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (deviceId_ != 0L) {
          output.writeInt64(1, deviceId_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (deviceId_ != 0L) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(1, deviceId_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory)) {
          return super.equals(obj);
        }
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory other = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) obj;

        boolean result = true;
        result = result && (getDeviceId()
            == other.getDeviceId());
        result = result && unknownFields.equals(other.unknownFields);
        return result;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + DEVICE_ID_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDeviceId());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory)
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder.class);
        }

        // Construct using nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          deviceId_ = 0L;

          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getDefaultInstanceForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory build() {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory buildPartial() {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory result = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory(this);
          result.deviceId_ = deviceId_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return (Builder) super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) {
            return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory other) {
          if (other == nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance()) return this;
          if (other.getDeviceId() != 0L) {
            setDeviceId(other.getDeviceId());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private long deviceId_ ;
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 device_id
         *&#64;&#64;
         *&#64;&#64;     The GPU device ID on which the cudaIPC handle was created.
         *&#64;&#64;
         * </pre>
         *
         * <code>int64 device_id = 1;</code>
         */
        public long getDeviceId() {
          return deviceId_;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 device_id
         *&#64;&#64;
         *&#64;&#64;     The GPU device ID on which the cudaIPC handle was created.
         *&#64;&#64;
         * </pre>
         *
         * <code>int64 device_id = 1;</code>
         */
        public Builder setDeviceId(long value) {
          
          deviceId_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 device_id
         *&#64;&#64;
         *&#64;&#64;     The GPU device ID on which the cudaIPC handle was created.
         *&#64;&#64;
         * </pre>
         *
         * <code>int64 device_id = 1;</code>
         */
        public Builder clearDeviceId() {
          
          deviceId_ = 0L;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFieldsProto3(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory)
      }

      // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory)
      private static final nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory();
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<CudaSharedMemory>
          PARSER = new com.google.protobuf.AbstractParser<CudaSharedMemory>() {
        @java.lang.Override
        public CudaSharedMemory parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new CudaSharedMemory(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<CudaSharedMemory> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<CudaSharedMemory> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int sharedMemoryTypesCase_ = 0;
    private java.lang.Object sharedMemoryTypes_;
    public enum SharedMemoryTypesCase
        implements com.google.protobuf.Internal.EnumLite {
      SYSTEM_SHARED_MEMORY(2),
      CUDA_SHARED_MEMORY(3),
      SHAREDMEMORYTYPES_NOT_SET(0);
      private final int value;
      private SharedMemoryTypesCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static SharedMemoryTypesCase valueOf(int value) {
        return forNumber(value);
      }

      public static SharedMemoryTypesCase forNumber(int value) {
        switch (value) {
          case 2: return SYSTEM_SHARED_MEMORY;
          case 3: return CUDA_SHARED_MEMORY;
          case 0: return SHAREDMEMORYTYPES_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public SharedMemoryTypesCase
    getSharedMemoryTypesCase() {
      return SharedMemoryTypesCase.forNumber(
          sharedMemoryTypesCase_);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name for this shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name for this shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SYSTEM_SHARED_MEMORY_FIELD_NUMBER = 2;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    public boolean hasSystemSharedMemory() {
      return sharedMemoryTypesCase_ == 2;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getSystemSharedMemory() {
      if (sharedMemoryTypesCase_ == 2) {
         return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_;
      }
      return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this system shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder getSystemSharedMemoryOrBuilder() {
      if (sharedMemoryTypesCase_ == 2) {
         return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_;
      }
      return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
    }

    public static final int CUDA_SHARED_MEMORY_FIELD_NUMBER = 3;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    public boolean hasCudaSharedMemory() {
      return sharedMemoryTypesCase_ == 3;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getCudaSharedMemory() {
      if (sharedMemoryTypesCase_ == 3) {
         return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_;
      }
      return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
     *&#64;&#64;
     *&#64;&#64;     The status of this CUDA shared memory region.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder getCudaSharedMemoryOrBuilder() {
      if (sharedMemoryTypesCase_ == 3) {
         return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_;
      }
      return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
    }

    public static final int BYTE_SIZE_FIELD_NUMBER = 5;
    private long byteSize_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 byte_size
     *&#64;&#64;
     *&#64;&#64;     Size of the shared memory block, in bytes.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 byte_size = 5;</code>
     */
    public long getByteSize() {
      return byteSize_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (sharedMemoryTypesCase_ == 2) {
        output.writeMessage(2, (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_);
      }
      if (sharedMemoryTypesCase_ == 3) {
        output.writeMessage(3, (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_);
      }
      if (byteSize_ != 0L) {
        output.writeUInt64(5, byteSize_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (sharedMemoryTypesCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_);
      }
      if (sharedMemoryTypesCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_);
      }
      if (byteSize_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, byteSize_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion other = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && (getByteSize()
          == other.getByteSize());
      result = result && getSharedMemoryTypesCase().equals(
          other.getSharedMemoryTypesCase());
      if (!result) return false;
      switch (sharedMemoryTypesCase_) {
        case 2:
          result = result && getSystemSharedMemory()
              .equals(other.getSystemSharedMemory());
          break;
        case 3:
          result = result && getCudaSharedMemory()
              .equals(other.getCudaSharedMemory());
          break;
        case 0:
        default:
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + BYTE_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getByteSize());
      switch (sharedMemoryTypesCase_) {
        case 2:
          hash = (37 * hash) + SYSTEM_SHARED_MEMORY_FIELD_NUMBER;
          hash = (53 * hash) + getSystemSharedMemory().hashCode();
          break;
        case 3:
          hash = (37 * hash) + CUDA_SHARED_MEMORY_FIELD_NUMBER;
          hash = (53 * hash) + getCudaSharedMemory().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;.. cpp:var:: message SharedMemoryRegion
     *&#64;&#64;
     *&#64;&#64;   The meta-data for the shared memory region registered in the inference
     *&#64;&#64;   server.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.SharedMemoryRegion}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.SharedMemoryRegion)
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        byteSize_ = 0L;

        sharedMemoryTypesCase_ = 0;
        sharedMemoryTypes_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion build() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion result = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion(this);
        result.name_ = name_;
        if (sharedMemoryTypesCase_ == 2) {
          if (systemSharedMemoryBuilder_ == null) {
            result.sharedMemoryTypes_ = sharedMemoryTypes_;
          } else {
            result.sharedMemoryTypes_ = systemSharedMemoryBuilder_.build();
          }
        }
        if (sharedMemoryTypesCase_ == 3) {
          if (cudaSharedMemoryBuilder_ == null) {
            result.sharedMemoryTypes_ = sharedMemoryTypes_;
          } else {
            result.sharedMemoryTypes_ = cudaSharedMemoryBuilder_.build();
          }
        }
        result.byteSize_ = byteSize_;
        result.sharedMemoryTypesCase_ = sharedMemoryTypesCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.getByteSize() != 0L) {
          setByteSize(other.getByteSize());
        }
        switch (other.getSharedMemoryTypesCase()) {
          case SYSTEM_SHARED_MEMORY: {
            mergeSystemSharedMemory(other.getSystemSharedMemory());
            break;
          }
          case CUDA_SHARED_MEMORY: {
            mergeCudaSharedMemory(other.getCudaSharedMemory());
            break;
          }
          case SHAREDMEMORYTYPES_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int sharedMemoryTypesCase_ = 0;
      private java.lang.Object sharedMemoryTypes_;
      public SharedMemoryTypesCase
          getSharedMemoryTypesCase() {
        return SharedMemoryTypesCase.forNumber(
            sharedMemoryTypesCase_);
      }

      public Builder clearSharedMemoryTypes() {
        sharedMemoryTypesCase_ = 0;
        sharedMemoryTypes_ = null;
        onChanged();
        return this;
      }


      private java.lang.Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name for this shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name for this shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name for this shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name for this shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name for this shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder> systemSharedMemoryBuilder_;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public boolean hasSystemSharedMemory() {
        return sharedMemoryTypesCase_ == 2;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory getSystemSharedMemory() {
        if (systemSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 2) {
            return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_;
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
        } else {
          if (sharedMemoryTypesCase_ == 2) {
            return systemSharedMemoryBuilder_.getMessage();
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public Builder setSystemSharedMemory(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory value) {
        if (systemSharedMemoryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          sharedMemoryTypes_ = value;
          onChanged();
        } else {
          systemSharedMemoryBuilder_.setMessage(value);
        }
        sharedMemoryTypesCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public Builder setSystemSharedMemory(
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder builderForValue) {
        if (systemSharedMemoryBuilder_ == null) {
          sharedMemoryTypes_ = builderForValue.build();
          onChanged();
        } else {
          systemSharedMemoryBuilder_.setMessage(builderForValue.build());
        }
        sharedMemoryTypesCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public Builder mergeSystemSharedMemory(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory value) {
        if (systemSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 2 &&
              sharedMemoryTypes_ != nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance()) {
            sharedMemoryTypes_ = nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.newBuilder((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_)
                .mergeFrom(value).buildPartial();
          } else {
            sharedMemoryTypes_ = value;
          }
          onChanged();
        } else {
          if (sharedMemoryTypesCase_ == 2) {
            systemSharedMemoryBuilder_.mergeFrom(value);
          }
          systemSharedMemoryBuilder_.setMessage(value);
        }
        sharedMemoryTypesCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public Builder clearSystemSharedMemory() {
        if (systemSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 2) {
            sharedMemoryTypesCase_ = 0;
            sharedMemoryTypes_ = null;
            onChanged();
          }
        } else {
          if (sharedMemoryTypesCase_ == 2) {
            sharedMemoryTypesCase_ = 0;
            sharedMemoryTypes_ = null;
          }
          systemSharedMemoryBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder getSystemSharedMemoryBuilder() {
        return getSystemSharedMemoryFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder getSystemSharedMemoryOrBuilder() {
        if ((sharedMemoryTypesCase_ == 2) && (systemSharedMemoryBuilder_ != null)) {
          return systemSharedMemoryBuilder_.getMessageOrBuilder();
        } else {
          if (sharedMemoryTypesCase_ == 2) {
            return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_;
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SystemSharedMemory system_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this system shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.SystemSharedMemory system_shared_memory = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder> 
          getSystemSharedMemoryFieldBuilder() {
        if (systemSharedMemoryBuilder_ == null) {
          if (!(sharedMemoryTypesCase_ == 2)) {
            sharedMemoryTypes_ = nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.getDefaultInstance();
          }
          systemSharedMemoryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemoryOrBuilder>(
                  (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.SystemSharedMemory) sharedMemoryTypes_,
                  getParentForChildren(),
                  isClean());
          sharedMemoryTypes_ = null;
        }
        sharedMemoryTypesCase_ = 2;
        onChanged();;
        return systemSharedMemoryBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder> cudaSharedMemoryBuilder_;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public boolean hasCudaSharedMemory() {
        return sharedMemoryTypesCase_ == 3;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory getCudaSharedMemory() {
        if (cudaSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 3) {
            return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_;
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
        } else {
          if (sharedMemoryTypesCase_ == 3) {
            return cudaSharedMemoryBuilder_.getMessage();
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public Builder setCudaSharedMemory(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory value) {
        if (cudaSharedMemoryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          sharedMemoryTypes_ = value;
          onChanged();
        } else {
          cudaSharedMemoryBuilder_.setMessage(value);
        }
        sharedMemoryTypesCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public Builder setCudaSharedMemory(
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder builderForValue) {
        if (cudaSharedMemoryBuilder_ == null) {
          sharedMemoryTypes_ = builderForValue.build();
          onChanged();
        } else {
          cudaSharedMemoryBuilder_.setMessage(builderForValue.build());
        }
        sharedMemoryTypesCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public Builder mergeCudaSharedMemory(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory value) {
        if (cudaSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 3 &&
              sharedMemoryTypes_ != nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance()) {
            sharedMemoryTypes_ = nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.newBuilder((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_)
                .mergeFrom(value).buildPartial();
          } else {
            sharedMemoryTypes_ = value;
          }
          onChanged();
        } else {
          if (sharedMemoryTypesCase_ == 3) {
            cudaSharedMemoryBuilder_.mergeFrom(value);
          }
          cudaSharedMemoryBuilder_.setMessage(value);
        }
        sharedMemoryTypesCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public Builder clearCudaSharedMemory() {
        if (cudaSharedMemoryBuilder_ == null) {
          if (sharedMemoryTypesCase_ == 3) {
            sharedMemoryTypesCase_ = 0;
            sharedMemoryTypes_ = null;
            onChanged();
          }
        } else {
          if (sharedMemoryTypesCase_ == 3) {
            sharedMemoryTypesCase_ = 0;
            sharedMemoryTypes_ = null;
          }
          cudaSharedMemoryBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder getCudaSharedMemoryBuilder() {
        return getCudaSharedMemoryFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder getCudaSharedMemoryOrBuilder() {
        if ((sharedMemoryTypesCase_ == 3) && (cudaSharedMemoryBuilder_ != null)) {
          return cudaSharedMemoryBuilder_.getMessageOrBuilder();
        } else {
          if (sharedMemoryTypesCase_ == 3) {
            return (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_;
          }
          return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: CudaSharedMemory cuda_shared_memory
       *&#64;&#64;
       *&#64;&#64;     The status of this CUDA shared memory region.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryRegion.CudaSharedMemory cuda_shared_memory = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder> 
          getCudaSharedMemoryFieldBuilder() {
        if (cudaSharedMemoryBuilder_ == null) {
          if (!(sharedMemoryTypesCase_ == 3)) {
            sharedMemoryTypes_ = nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.getDefaultInstance();
          }
          cudaSharedMemoryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemoryOrBuilder>(
                  (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.CudaSharedMemory) sharedMemoryTypes_,
                  getParentForChildren(),
                  isClean());
          sharedMemoryTypes_ = null;
        }
        sharedMemoryTypesCase_ = 3;
        onChanged();;
        return cudaSharedMemoryBuilder_;
      }

      private long byteSize_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 byte_size
       *&#64;&#64;
       *&#64;&#64;     Size of the shared memory block, in bytes.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 byte_size = 5;</code>
       */
      public long getByteSize() {
        return byteSize_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 byte_size
       *&#64;&#64;
       *&#64;&#64;     Size of the shared memory block, in bytes.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 byte_size = 5;</code>
       */
      public Builder setByteSize(long value) {
        
        byteSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 byte_size
       *&#64;&#64;
       *&#64;&#64;     Size of the shared memory block, in bytes.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 byte_size = 5;</code>
       */
      public Builder clearByteSize() {
        
        byteSize_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.SharedMemoryRegion)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.SharedMemoryRegion)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SharedMemoryRegion>
        PARSER = new com.google.protobuf.AbstractParser<SharedMemoryRegion>() {
      @java.lang.Override
      public SharedMemoryRegion parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SharedMemoryRegion(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SharedMemoryRegion> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SharedMemoryRegion> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ServerStatusOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ServerStatus)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string id
     *&#64;&#64;
     *&#64;&#64;     The server's ID.
     *&#64;&#64;
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    java.lang.String getId();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string id
     *&#64;&#64;
     *&#64;&#64;     The server's ID.
     *&#64;&#64;
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string version
     *&#64;&#64;
     *&#64;&#64;     The server's version.
     *&#64;&#64;
     * </pre>
     *
     * <code>string version = 2;</code>
     */
    java.lang.String getVersion();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string version
     *&#64;&#64;
     *&#64;&#64;     The server's version.
     *&#64;&#64;
     * </pre>
     *
     * <code>string version = 2;</code>
     */
    com.google.protobuf.ByteString
        getVersionBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the server.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
     */
    int getReadyStateValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the server.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState getReadyState();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 uptime_ns
     *&#64;&#64;
     *&#64;&#64;     Server uptime in nanoseconds.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 uptime_ns = 3;</code>
     */
    long getUptimeNs();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */
    int getModelStatusCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */
    boolean containsModelStatus(
        java.lang.String key);
    /**
     * Use {@link #getModelStatusMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
    getModelStatus();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */
    java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
    getModelStatusMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrDefault(
        java.lang.String key,
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrThrow(
        java.lang.String key);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    boolean hasStatusStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getStatusStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder getStatusStatsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    boolean hasHealthStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getHealthStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder getHealthStatsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    boolean hasModelControlStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getModelControlStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder getModelControlStatsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    boolean hasShmControlStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getShmControlStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder getShmControlStatsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    boolean hasRepositoryStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getRepositoryStats();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder getRepositoryStatsOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ServerStatus
   *&#64;&#64;
   *&#64;&#64;   Status for the inference server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ServerStatus}
   */
  public  static final class ServerStatus extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ServerStatus)
      ServerStatusOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ServerStatus.newBuilder() to construct.
    private ServerStatus(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ServerStatus() {
      id_ = "";
      version_ = "";
      readyState_ = 0;
      uptimeNs_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ServerStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              version_ = s;
              break;
            }
            case 24: {

              uptimeNs_ = input.readUInt64();
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                modelStatus_ = com.google.protobuf.MapField.newMapField(
                    ModelStatusDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000010;
              }
              com.google.protobuf.MapEntry<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
              modelStatus__ = input.readMessage(
                  ModelStatusDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              modelStatus_.getMutableMap().put(
                  modelStatus__.getKey(), modelStatus__.getValue());
              break;
            }
            case 42: {
              nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder subBuilder = null;
              if (statusStats_ != null) {
                subBuilder = statusStats_.toBuilder();
              }
              statusStats_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(statusStats_);
                statusStats_ = subBuilder.buildPartial();
              }

              break;
            }
            case 56: {
              int rawValue = input.readEnum();

              readyState_ = rawValue;
              break;
            }
            case 66: {
              nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder subBuilder = null;
              if (healthStats_ != null) {
                subBuilder = healthStats_.toBuilder();
              }
              healthStats_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(healthStats_);
                healthStats_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder subBuilder = null;
              if (modelControlStats_ != null) {
                subBuilder = modelControlStats_.toBuilder();
              }
              modelControlStats_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modelControlStats_);
                modelControlStats_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder subBuilder = null;
              if (shmControlStats_ != null) {
                subBuilder = shmControlStats_.toBuilder();
              }
              shmControlStats_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(shmControlStats_);
                shmControlStats_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder subBuilder = null;
              if (repositoryStats_ != null) {
                subBuilder = repositoryStats_.toBuilder();
              }
              repositoryStats_ = input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(repositoryStats_);
                repositoryStats_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 4:
          return internalGetModelStatus();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string id
     *&#64;&#64;
     *&#64;&#64;     The server's ID.
     *&#64;&#64;
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string id
     *&#64;&#64;
     *&#64;&#64;     The server's ID.
     *&#64;&#64;
     * </pre>
     *
     * <code>string id = 1;</code>
     */
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VERSION_FIELD_NUMBER = 2;
    private volatile java.lang.Object version_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string version
     *&#64;&#64;
     *&#64;&#64;     The server's version.
     *&#64;&#64;
     * </pre>
     *
     * <code>string version = 2;</code>
     */
    public java.lang.String getVersion() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        version_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string version
     *&#64;&#64;
     *&#64;&#64;     The server's version.
     *&#64;&#64;
     * </pre>
     *
     * <code>string version = 2;</code>
     */
    public com.google.protobuf.ByteString
        getVersionBytes() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        version_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int READY_STATE_FIELD_NUMBER = 7;
    private int readyState_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the server.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
     */
    public int getReadyStateValue() {
      return readyState_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
     *&#64;&#64;
     *&#64;&#64;     Current readiness state for the server.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState getReadyState() {
      @SuppressWarnings("deprecation")
      nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState result = nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.valueOf(readyState_);
      return result == null ? nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.UNRECOGNIZED : result;
    }

    public static final int UPTIME_NS_FIELD_NUMBER = 3;
    private long uptimeNs_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 uptime_ns
     *&#64;&#64;
     *&#64;&#64;     Server uptime in nanoseconds.
     *&#64;&#64;
     * </pre>
     *
     * <code>uint64 uptime_ns = 3;</code>
     */
    public long getUptimeNs() {
      return uptimeNs_;
    }

    public static final int MODEL_STATUS_FIELD_NUMBER = 4;
    private static final class ModelStatusDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>newDefaultInstance(
                  nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> modelStatus_;
    private com.google.protobuf.MapField<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
    internalGetModelStatus() {
      if (modelStatus_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            ModelStatusDefaultEntryHolder.defaultEntry);
      }
      return modelStatus_;
    }

    public int getModelStatusCount() {
      return internalGetModelStatus().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    public boolean containsModelStatus(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      return internalGetModelStatus().getMap().containsKey(key);
    }
    /**
     * Use {@link #getModelStatusMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> getModelStatus() {
      return getModelStatusMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    public java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> getModelStatusMap() {
      return internalGetModelStatus().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrDefault(
        java.lang.String key,
        nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus defaultValue) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> map =
          internalGetModelStatus().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
     *&#64;&#64;
     *&#64;&#64;     Status for each model, as a map from model name to the
     *&#64;&#64;     status.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
     */

    public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrThrow(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> map =
          internalGetModelStatus().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int STATUS_STATS_FIELD_NUMBER = 5;
    private nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats statusStats_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    public boolean hasStatusStats() {
      return statusStats_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getStatusStats() {
      return statusStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.getDefaultInstance() : statusStats_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Status requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder getStatusStatsOrBuilder() {
      return getStatusStats();
    }

    public static final int HEALTH_STATS_FIELD_NUMBER = 8;
    private nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats healthStats_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    public boolean hasHealthStats() {
      return healthStats_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getHealthStats() {
      return healthStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.getDefaultInstance() : healthStats_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Health requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder getHealthStatsOrBuilder() {
      return getHealthStats();
    }

    public static final int MODEL_CONTROL_STATS_FIELD_NUMBER = 9;
    private nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats modelControlStats_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    public boolean hasModelControlStats() {
      return modelControlStats_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getModelControlStats() {
      return modelControlStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.getDefaultInstance() : modelControlStats_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for ModelControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder getModelControlStatsOrBuilder() {
      return getModelControlStats();
    }

    public static final int SHM_CONTROL_STATS_FIELD_NUMBER = 10;
    private nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats shmControlStats_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    public boolean hasShmControlStats() {
      return shmControlStats_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getShmControlStats() {
      return shmControlStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.getDefaultInstance() : shmControlStats_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for SharedMemoryControl requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder getShmControlStatsOrBuilder() {
      return getShmControlStats();
    }

    public static final int REPOSITORY_STATS_FIELD_NUMBER = 11;
    private nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats repositoryStats_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    public boolean hasRepositoryStats() {
      return repositoryStats_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getRepositoryStats() {
      return repositoryStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.getDefaultInstance() : repositoryStats_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
     *&#64;&#64;
     *&#64;&#64;     Statistics for Repository requests.
     *&#64;&#64;
     * </pre>
     *
     * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder getRepositoryStatsOrBuilder() {
      return getRepositoryStats();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getIdBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      if (!getVersionBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, version_);
      }
      if (uptimeNs_ != 0L) {
        output.writeUInt64(3, uptimeNs_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetModelStatus(),
          ModelStatusDefaultEntryHolder.defaultEntry,
          4);
      if (statusStats_ != null) {
        output.writeMessage(5, getStatusStats());
      }
      if (readyState_ != nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.SERVER_INVALID.getNumber()) {
        output.writeEnum(7, readyState_);
      }
      if (healthStats_ != null) {
        output.writeMessage(8, getHealthStats());
      }
      if (modelControlStats_ != null) {
        output.writeMessage(9, getModelControlStats());
      }
      if (shmControlStats_ != null) {
        output.writeMessage(10, getShmControlStats());
      }
      if (repositoryStats_ != null) {
        output.writeMessage(11, getRepositoryStats());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getIdBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      if (!getVersionBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, version_);
      }
      if (uptimeNs_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, uptimeNs_);
      }
      for (java.util.Map.Entry<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> entry
           : internalGetModelStatus().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
        modelStatus__ = ModelStatusDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(4, modelStatus__);
      }
      if (statusStats_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getStatusStats());
      }
      if (readyState_ != nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.SERVER_INVALID.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, readyState_);
      }
      if (healthStats_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getHealthStats());
      }
      if (modelControlStats_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getModelControlStats());
      }
      if (shmControlStats_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getShmControlStats());
      }
      if (repositoryStats_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getRepositoryStats());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus other = (nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus) obj;

      boolean result = true;
      result = result && getId()
          .equals(other.getId());
      result = result && getVersion()
          .equals(other.getVersion());
      result = result && readyState_ == other.readyState_;
      result = result && (getUptimeNs()
          == other.getUptimeNs());
      result = result && internalGetModelStatus().equals(
          other.internalGetModelStatus());
      result = result && (hasStatusStats() == other.hasStatusStats());
      if (hasStatusStats()) {
        result = result && getStatusStats()
            .equals(other.getStatusStats());
      }
      result = result && (hasHealthStats() == other.hasHealthStats());
      if (hasHealthStats()) {
        result = result && getHealthStats()
            .equals(other.getHealthStats());
      }
      result = result && (hasModelControlStats() == other.hasModelControlStats());
      if (hasModelControlStats()) {
        result = result && getModelControlStats()
            .equals(other.getModelControlStats());
      }
      result = result && (hasShmControlStats() == other.hasShmControlStats());
      if (hasShmControlStats()) {
        result = result && getShmControlStats()
            .equals(other.getShmControlStats());
      }
      result = result && (hasRepositoryStats() == other.hasRepositoryStats());
      if (hasRepositoryStats()) {
        result = result && getRepositoryStats()
            .equals(other.getRepositoryStats());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      hash = (37 * hash) + VERSION_FIELD_NUMBER;
      hash = (53 * hash) + getVersion().hashCode();
      hash = (37 * hash) + READY_STATE_FIELD_NUMBER;
      hash = (53 * hash) + readyState_;
      hash = (37 * hash) + UPTIME_NS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getUptimeNs());
      if (!internalGetModelStatus().getMap().isEmpty()) {
        hash = (37 * hash) + MODEL_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetModelStatus().hashCode();
      }
      if (hasStatusStats()) {
        hash = (37 * hash) + STATUS_STATS_FIELD_NUMBER;
        hash = (53 * hash) + getStatusStats().hashCode();
      }
      if (hasHealthStats()) {
        hash = (37 * hash) + HEALTH_STATS_FIELD_NUMBER;
        hash = (53 * hash) + getHealthStats().hashCode();
      }
      if (hasModelControlStats()) {
        hash = (37 * hash) + MODEL_CONTROL_STATS_FIELD_NUMBER;
        hash = (53 * hash) + getModelControlStats().hashCode();
      }
      if (hasShmControlStats()) {
        hash = (37 * hash) + SHM_CONTROL_STATS_FIELD_NUMBER;
        hash = (53 * hash) + getShmControlStats().hashCode();
      }
      if (hasRepositoryStats()) {
        hash = (37 * hash) + REPOSITORY_STATS_FIELD_NUMBER;
        hash = (53 * hash) + getRepositoryStats().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ServerStatus
     *&#64;&#64;
     *&#64;&#64;   Status for the inference server.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ServerStatus}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ServerStatus)
        nvidia.inferenceserver.ServerStatusOuterClass.ServerStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 4:
            return internalGetModelStatus();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 4:
            return internalGetMutableModelStatus();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        version_ = "";

        readyState_ = 0;

        uptimeNs_ = 0L;

        internalGetMutableModelStatus().clear();
        if (statusStatsBuilder_ == null) {
          statusStats_ = null;
        } else {
          statusStats_ = null;
          statusStatsBuilder_ = null;
        }
        if (healthStatsBuilder_ == null) {
          healthStats_ = null;
        } else {
          healthStats_ = null;
          healthStatsBuilder_ = null;
        }
        if (modelControlStatsBuilder_ == null) {
          modelControlStats_ = null;
        } else {
          modelControlStats_ = null;
          modelControlStatsBuilder_ = null;
        }
        if (shmControlStatsBuilder_ == null) {
          shmControlStats_ = null;
        } else {
          shmControlStats_ = null;
          shmControlStatsBuilder_ = null;
        }
        if (repositoryStatsBuilder_ == null) {
          repositoryStats_ = null;
        } else {
          repositoryStats_ = null;
          repositoryStatsBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ServerStatus_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus result = new nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.id_ = id_;
        result.version_ = version_;
        result.readyState_ = readyState_;
        result.uptimeNs_ = uptimeNs_;
        result.modelStatus_ = internalGetModelStatus();
        result.modelStatus_.makeImmutable();
        if (statusStatsBuilder_ == null) {
          result.statusStats_ = statusStats_;
        } else {
          result.statusStats_ = statusStatsBuilder_.build();
        }
        if (healthStatsBuilder_ == null) {
          result.healthStats_ = healthStats_;
        } else {
          result.healthStats_ = healthStatsBuilder_.build();
        }
        if (modelControlStatsBuilder_ == null) {
          result.modelControlStats_ = modelControlStats_;
        } else {
          result.modelControlStats_ = modelControlStatsBuilder_.build();
        }
        if (shmControlStatsBuilder_ == null) {
          result.shmControlStats_ = shmControlStats_;
        } else {
          result.shmControlStats_ = shmControlStatsBuilder_.build();
        }
        if (repositoryStatsBuilder_ == null) {
          result.repositoryStats_ = repositoryStats_;
        } else {
          result.repositoryStats_ = repositoryStatsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (!other.getVersion().isEmpty()) {
          version_ = other.version_;
          onChanged();
        }
        if (other.readyState_ != 0) {
          setReadyStateValue(other.getReadyStateValue());
        }
        if (other.getUptimeNs() != 0L) {
          setUptimeNs(other.getUptimeNs());
        }
        internalGetMutableModelStatus().mergeFrom(
            other.internalGetModelStatus());
        if (other.hasStatusStats()) {
          mergeStatusStats(other.getStatusStats());
        }
        if (other.hasHealthStats()) {
          mergeHealthStats(other.getHealthStats());
        }
        if (other.hasModelControlStats()) {
          mergeModelControlStats(other.getModelControlStats());
        }
        if (other.hasShmControlStats()) {
          mergeShmControlStats(other.getShmControlStats());
        }
        if (other.hasRepositoryStats()) {
          mergeRepositoryStats(other.getRepositoryStats());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object id_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string id
       *&#64;&#64;
       *&#64;&#64;     The server's ID.
       *&#64;&#64;
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string id
       *&#64;&#64;
       *&#64;&#64;     The server's ID.
       *&#64;&#64;
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string id
       *&#64;&#64;
       *&#64;&#64;     The server's ID.
       *&#64;&#64;
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string id
       *&#64;&#64;
       *&#64;&#64;     The server's ID.
       *&#64;&#64;
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string id
       *&#64;&#64;
       *&#64;&#64;     The server's ID.
       *&#64;&#64;
       * </pre>
       *
       * <code>string id = 1;</code>
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object version_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string version
       *&#64;&#64;
       *&#64;&#64;     The server's version.
       *&#64;&#64;
       * </pre>
       *
       * <code>string version = 2;</code>
       */
      public java.lang.String getVersion() {
        java.lang.Object ref = version_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          version_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string version
       *&#64;&#64;
       *&#64;&#64;     The server's version.
       *&#64;&#64;
       * </pre>
       *
       * <code>string version = 2;</code>
       */
      public com.google.protobuf.ByteString
          getVersionBytes() {
        java.lang.Object ref = version_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          version_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string version
       *&#64;&#64;
       *&#64;&#64;     The server's version.
       *&#64;&#64;
       * </pre>
       *
       * <code>string version = 2;</code>
       */
      public Builder setVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string version
       *&#64;&#64;
       *&#64;&#64;     The server's version.
       *&#64;&#64;
       * </pre>
       *
       * <code>string version = 2;</code>
       */
      public Builder clearVersion() {
        
        version_ = getDefaultInstance().getVersion();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string version
       *&#64;&#64;
       *&#64;&#64;     The server's version.
       *&#64;&#64;
       * </pre>
       *
       * <code>string version = 2;</code>
       */
      public Builder setVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        version_ = value;
        onChanged();
        return this;
      }

      private int readyState_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the server.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
       */
      public int getReadyStateValue() {
        return readyState_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the server.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
       */
      public Builder setReadyStateValue(int value) {
        readyState_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the server.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState getReadyState() {
        @SuppressWarnings("deprecation")
        nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState result = nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.valueOf(readyState_);
        return result == null ? nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the server.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
       */
      public Builder setReadyState(nvidia.inferenceserver.ServerStatusOuterClass.ServerReadyState value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        readyState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ServerReadyState ready_state
       *&#64;&#64;
       *&#64;&#64;     Current readiness state for the server.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ServerReadyState ready_state = 7;</code>
       */
      public Builder clearReadyState() {
        
        readyState_ = 0;
        onChanged();
        return this;
      }

      private long uptimeNs_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 uptime_ns
       *&#64;&#64;
       *&#64;&#64;     Server uptime in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 uptime_ns = 3;</code>
       */
      public long getUptimeNs() {
        return uptimeNs_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 uptime_ns
       *&#64;&#64;
       *&#64;&#64;     Server uptime in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 uptime_ns = 3;</code>
       */
      public Builder setUptimeNs(long value) {
        
        uptimeNs_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 uptime_ns
       *&#64;&#64;
       *&#64;&#64;     Server uptime in nanoseconds.
       *&#64;&#64;
       * </pre>
       *
       * <code>uint64 uptime_ns = 3;</code>
       */
      public Builder clearUptimeNs() {
        
        uptimeNs_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> modelStatus_;
      private com.google.protobuf.MapField<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
      internalGetModelStatus() {
        if (modelStatus_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              ModelStatusDefaultEntryHolder.defaultEntry);
        }
        return modelStatus_;
      }
      private com.google.protobuf.MapField<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
      internalGetMutableModelStatus() {
        onChanged();;
        if (modelStatus_ == null) {
          modelStatus_ = com.google.protobuf.MapField.newMapField(
              ModelStatusDefaultEntryHolder.defaultEntry);
        }
        if (!modelStatus_.isMutable()) {
          modelStatus_ = modelStatus_.copy();
        }
        return modelStatus_;
      }

      public int getModelStatusCount() {
        return internalGetModelStatus().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public boolean containsModelStatus(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        return internalGetModelStatus().getMap().containsKey(key);
      }
      /**
       * Use {@link #getModelStatusMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> getModelStatus() {
        return getModelStatusMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> getModelStatusMap() {
        return internalGetModelStatus().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrDefault(
          java.lang.String key,
          nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus defaultValue) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> map =
            internalGetModelStatus().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus getModelStatusOrThrow(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> map =
            internalGetModelStatus().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearModelStatus() {
        internalGetMutableModelStatus().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public Builder removeModelStatus(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableModelStatus().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus>
      getMutableModelStatus() {
        return internalGetMutableModelStatus().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */
      public Builder putModelStatus(
          java.lang.String key,
          nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus value) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        if (value == null) { throw new java.lang.NullPointerException(); }
        internalGetMutableModelStatus().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, ModelStatus&gt; model_status
       *&#64;&#64;
       *&#64;&#64;     Status for each model, as a map from model name to the
       *&#64;&#64;     status.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .nvidia.inferenceserver.ModelStatus&gt; model_status = 4;</code>
       */

      public Builder putAllModelStatus(
          java.util.Map<java.lang.String, nvidia.inferenceserver.ServerStatusOuterClass.ModelStatus> values) {
        internalGetMutableModelStatus().getMutableMap()
            .putAll(values);
        return this;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats statusStats_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder> statusStatsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public boolean hasStatusStats() {
        return statusStatsBuilder_ != null || statusStats_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats getStatusStats() {
        if (statusStatsBuilder_ == null) {
          return statusStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.getDefaultInstance() : statusStats_;
        } else {
          return statusStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public Builder setStatusStats(nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats value) {
        if (statusStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          statusStats_ = value;
          onChanged();
        } else {
          statusStatsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public Builder setStatusStats(
          nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder builderForValue) {
        if (statusStatsBuilder_ == null) {
          statusStats_ = builderForValue.build();
          onChanged();
        } else {
          statusStatsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public Builder mergeStatusStats(nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats value) {
        if (statusStatsBuilder_ == null) {
          if (statusStats_ != null) {
            statusStats_ =
              nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.newBuilder(statusStats_).mergeFrom(value).buildPartial();
          } else {
            statusStats_ = value;
          }
          onChanged();
        } else {
          statusStatsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public Builder clearStatusStats() {
        if (statusStatsBuilder_ == null) {
          statusStats_ = null;
          onChanged();
        } else {
          statusStats_ = null;
          statusStatsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder getStatusStatsBuilder() {
        
        onChanged();
        return getStatusStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder getStatusStatsOrBuilder() {
        if (statusStatsBuilder_ != null) {
          return statusStatsBuilder_.getMessageOrBuilder();
        } else {
          return statusStats_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.getDefaultInstance() : statusStats_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: StatusRequestStats status_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Status requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.StatusRequestStats status_stats = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder> 
          getStatusStatsFieldBuilder() {
        if (statusStatsBuilder_ == null) {
          statusStatsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.StatusRequestStatsOrBuilder>(
                  getStatusStats(),
                  getParentForChildren(),
                  isClean());
          statusStats_ = null;
        }
        return statusStatsBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats healthStats_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder> healthStatsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public boolean hasHealthStats() {
        return healthStatsBuilder_ != null || healthStats_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats getHealthStats() {
        if (healthStatsBuilder_ == null) {
          return healthStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.getDefaultInstance() : healthStats_;
        } else {
          return healthStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public Builder setHealthStats(nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats value) {
        if (healthStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          healthStats_ = value;
          onChanged();
        } else {
          healthStatsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public Builder setHealthStats(
          nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder builderForValue) {
        if (healthStatsBuilder_ == null) {
          healthStats_ = builderForValue.build();
          onChanged();
        } else {
          healthStatsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public Builder mergeHealthStats(nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats value) {
        if (healthStatsBuilder_ == null) {
          if (healthStats_ != null) {
            healthStats_ =
              nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.newBuilder(healthStats_).mergeFrom(value).buildPartial();
          } else {
            healthStats_ = value;
          }
          onChanged();
        } else {
          healthStatsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public Builder clearHealthStats() {
        if (healthStatsBuilder_ == null) {
          healthStats_ = null;
          onChanged();
        } else {
          healthStats_ = null;
          healthStatsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder getHealthStatsBuilder() {
        
        onChanged();
        return getHealthStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder getHealthStatsOrBuilder() {
        if (healthStatsBuilder_ != null) {
          return healthStatsBuilder_.getMessageOrBuilder();
        } else {
          return healthStats_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.getDefaultInstance() : healthStats_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: HealthRequestStats health_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Health requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.HealthRequestStats health_stats = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder> 
          getHealthStatsFieldBuilder() {
        if (healthStatsBuilder_ == null) {
          healthStatsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.HealthRequestStatsOrBuilder>(
                  getHealthStats(),
                  getParentForChildren(),
                  isClean());
          healthStats_ = null;
        }
        return healthStatsBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats modelControlStats_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder> modelControlStatsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public boolean hasModelControlStats() {
        return modelControlStatsBuilder_ != null || modelControlStats_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats getModelControlStats() {
        if (modelControlStatsBuilder_ == null) {
          return modelControlStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.getDefaultInstance() : modelControlStats_;
        } else {
          return modelControlStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public Builder setModelControlStats(nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats value) {
        if (modelControlStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modelControlStats_ = value;
          onChanged();
        } else {
          modelControlStatsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public Builder setModelControlStats(
          nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder builderForValue) {
        if (modelControlStatsBuilder_ == null) {
          modelControlStats_ = builderForValue.build();
          onChanged();
        } else {
          modelControlStatsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public Builder mergeModelControlStats(nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats value) {
        if (modelControlStatsBuilder_ == null) {
          if (modelControlStats_ != null) {
            modelControlStats_ =
              nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.newBuilder(modelControlStats_).mergeFrom(value).buildPartial();
          } else {
            modelControlStats_ = value;
          }
          onChanged();
        } else {
          modelControlStatsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public Builder clearModelControlStats() {
        if (modelControlStatsBuilder_ == null) {
          modelControlStats_ = null;
          onChanged();
        } else {
          modelControlStats_ = null;
          modelControlStatsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder getModelControlStatsBuilder() {
        
        onChanged();
        return getModelControlStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder getModelControlStatsOrBuilder() {
        if (modelControlStatsBuilder_ != null) {
          return modelControlStatsBuilder_.getMessageOrBuilder();
        } else {
          return modelControlStats_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.getDefaultInstance() : modelControlStats_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelControlRequestStats model_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for ModelControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.ModelControlRequestStats model_control_stats = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder> 
          getModelControlStatsFieldBuilder() {
        if (modelControlStatsBuilder_ == null) {
          modelControlStatsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelControlRequestStatsOrBuilder>(
                  getModelControlStats(),
                  getParentForChildren(),
                  isClean());
          modelControlStats_ = null;
        }
        return modelControlStatsBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats shmControlStats_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder> shmControlStatsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public boolean hasShmControlStats() {
        return shmControlStatsBuilder_ != null || shmControlStats_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats getShmControlStats() {
        if (shmControlStatsBuilder_ == null) {
          return shmControlStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.getDefaultInstance() : shmControlStats_;
        } else {
          return shmControlStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public Builder setShmControlStats(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats value) {
        if (shmControlStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          shmControlStats_ = value;
          onChanged();
        } else {
          shmControlStatsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public Builder setShmControlStats(
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder builderForValue) {
        if (shmControlStatsBuilder_ == null) {
          shmControlStats_ = builderForValue.build();
          onChanged();
        } else {
          shmControlStatsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public Builder mergeShmControlStats(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats value) {
        if (shmControlStatsBuilder_ == null) {
          if (shmControlStats_ != null) {
            shmControlStats_ =
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.newBuilder(shmControlStats_).mergeFrom(value).buildPartial();
          } else {
            shmControlStats_ = value;
          }
          onChanged();
        } else {
          shmControlStatsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public Builder clearShmControlStats() {
        if (shmControlStatsBuilder_ == null) {
          shmControlStats_ = null;
          onChanged();
        } else {
          shmControlStats_ = null;
          shmControlStatsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder getShmControlStatsBuilder() {
        
        onChanged();
        return getShmControlStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder getShmControlStatsOrBuilder() {
        if (shmControlStatsBuilder_ != null) {
          return shmControlStatsBuilder_.getMessageOrBuilder();
        } else {
          return shmControlStats_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.getDefaultInstance() : shmControlStats_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: SharedMemoryControlRequestStats shm_control_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for SharedMemoryControl requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.SharedMemoryControlRequestStats shm_control_stats = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder> 
          getShmControlStatsFieldBuilder() {
        if (shmControlStatsBuilder_ == null) {
          shmControlStatsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryControlRequestStatsOrBuilder>(
                  getShmControlStats(),
                  getParentForChildren(),
                  isClean());
          shmControlStats_ = null;
        }
        return shmControlStatsBuilder_;
      }

      private nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats repositoryStats_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder> repositoryStatsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public boolean hasRepositoryStats() {
        return repositoryStatsBuilder_ != null || repositoryStats_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats getRepositoryStats() {
        if (repositoryStatsBuilder_ == null) {
          return repositoryStats_ == null ? nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.getDefaultInstance() : repositoryStats_;
        } else {
          return repositoryStatsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public Builder setRepositoryStats(nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats value) {
        if (repositoryStatsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          repositoryStats_ = value;
          onChanged();
        } else {
          repositoryStatsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public Builder setRepositoryStats(
          nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder builderForValue) {
        if (repositoryStatsBuilder_ == null) {
          repositoryStats_ = builderForValue.build();
          onChanged();
        } else {
          repositoryStatsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public Builder mergeRepositoryStats(nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats value) {
        if (repositoryStatsBuilder_ == null) {
          if (repositoryStats_ != null) {
            repositoryStats_ =
              nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.newBuilder(repositoryStats_).mergeFrom(value).buildPartial();
          } else {
            repositoryStats_ = value;
          }
          onChanged();
        } else {
          repositoryStatsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public Builder clearRepositoryStats() {
        if (repositoryStatsBuilder_ == null) {
          repositoryStats_ = null;
          onChanged();
        } else {
          repositoryStats_ = null;
          repositoryStatsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder getRepositoryStatsBuilder() {
        
        onChanged();
        return getRepositoryStatsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder getRepositoryStatsOrBuilder() {
        if (repositoryStatsBuilder_ != null) {
          return repositoryStatsBuilder_.getMessageOrBuilder();
        } else {
          return repositoryStats_ == null ?
              nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.getDefaultInstance() : repositoryStats_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: RepositoryRequestStats repository_stats
       *&#64;&#64;
       *&#64;&#64;     Statistics for Repository requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>.nvidia.inferenceserver.RepositoryRequestStats repository_stats = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder> 
          getRepositoryStatsFieldBuilder() {
        if (repositoryStatsBuilder_ == null) {
          repositoryStatsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStats.Builder, nvidia.inferenceserver.ServerStatusOuterClass.RepositoryRequestStatsOrBuilder>(
                  getRepositoryStats(),
                  getParentForChildren(),
                  isClean());
          repositoryStats_ = null;
        }
        return repositoryStatsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ServerStatus)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ServerStatus)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ServerStatus>
        PARSER = new com.google.protobuf.AbstractParser<ServerStatus>() {
      @java.lang.Override
      public ServerStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ServerStatus(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ServerStatus> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ServerStatus> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ServerStatus getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SharedMemoryStatusOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.SharedMemoryStatus)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> 
        getSharedMemoryRegionList();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getSharedMemoryRegion(int index);
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    int getSharedMemoryRegionCount();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder> 
        getSharedMemoryRegionOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder getSharedMemoryRegionOrBuilder(
        int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message SharedMemoryStatus
   *&#64;&#64;
   *&#64;&#64;   Shared memory status for the inference server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.SharedMemoryStatus}
   */
  public  static final class SharedMemoryStatus extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.SharedMemoryStatus)
      SharedMemoryStatusOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SharedMemoryStatus.newBuilder() to construct.
    private SharedMemoryStatus(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SharedMemoryStatus() {
      sharedMemoryRegion_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SharedMemoryStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 18: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                sharedMemoryRegion_ = new java.util.ArrayList<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion>();
                mutable_bitField0_ |= 0x00000001;
              }
              sharedMemoryRegion_.add(
                  input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.parser(), extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          sharedMemoryRegion_ = java.util.Collections.unmodifiableList(sharedMemoryRegion_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.Builder.class);
    }

    public static final int SHARED_MEMORY_REGION_FIELD_NUMBER = 2;
    private java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> sharedMemoryRegion_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> getSharedMemoryRegionList() {
      return sharedMemoryRegion_;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    public java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder> 
        getSharedMemoryRegionOrBuilderList() {
      return sharedMemoryRegion_;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    public int getSharedMemoryRegionCount() {
      return sharedMemoryRegion_.size();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getSharedMemoryRegion(int index) {
      return sharedMemoryRegion_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of active/registered shared memory regions.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder getSharedMemoryRegionOrBuilder(
        int index) {
      return sharedMemoryRegion_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < sharedMemoryRegion_.size(); i++) {
        output.writeMessage(2, sharedMemoryRegion_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < sharedMemoryRegion_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, sharedMemoryRegion_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus other = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus) obj;

      boolean result = true;
      result = result && getSharedMemoryRegionList()
          .equals(other.getSharedMemoryRegionList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getSharedMemoryRegionCount() > 0) {
        hash = (37 * hash) + SHARED_MEMORY_REGION_FIELD_NUMBER;
        hash = (53 * hash) + getSharedMemoryRegionList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message SharedMemoryStatus
     *&#64;&#64;
     *&#64;&#64;   Shared memory status for the inference server.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.SharedMemoryStatus}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.SharedMemoryStatus)
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.class, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSharedMemoryRegionFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (sharedMemoryRegionBuilder_ == null) {
          sharedMemoryRegion_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          sharedMemoryRegionBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus build() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus result = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus(this);
        int from_bitField0_ = bitField0_;
        if (sharedMemoryRegionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            sharedMemoryRegion_ = java.util.Collections.unmodifiableList(sharedMemoryRegion_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.sharedMemoryRegion_ = sharedMemoryRegion_;
        } else {
          result.sharedMemoryRegion_ = sharedMemoryRegionBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus.getDefaultInstance()) return this;
        if (sharedMemoryRegionBuilder_ == null) {
          if (!other.sharedMemoryRegion_.isEmpty()) {
            if (sharedMemoryRegion_.isEmpty()) {
              sharedMemoryRegion_ = other.sharedMemoryRegion_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureSharedMemoryRegionIsMutable();
              sharedMemoryRegion_.addAll(other.sharedMemoryRegion_);
            }
            onChanged();
          }
        } else {
          if (!other.sharedMemoryRegion_.isEmpty()) {
            if (sharedMemoryRegionBuilder_.isEmpty()) {
              sharedMemoryRegionBuilder_.dispose();
              sharedMemoryRegionBuilder_ = null;
              sharedMemoryRegion_ = other.sharedMemoryRegion_;
              bitField0_ = (bitField0_ & ~0x00000001);
              sharedMemoryRegionBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSharedMemoryRegionFieldBuilder() : null;
            } else {
              sharedMemoryRegionBuilder_.addAllMessages(other.sharedMemoryRegion_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> sharedMemoryRegion_ =
        java.util.Collections.emptyList();
      private void ensureSharedMemoryRegionIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          sharedMemoryRegion_ = new java.util.ArrayList<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion>(sharedMemoryRegion_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder> sharedMemoryRegionBuilder_;

      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> getSharedMemoryRegionList() {
        if (sharedMemoryRegionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(sharedMemoryRegion_);
        } else {
          return sharedMemoryRegionBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public int getSharedMemoryRegionCount() {
        if (sharedMemoryRegionBuilder_ == null) {
          return sharedMemoryRegion_.size();
        } else {
          return sharedMemoryRegionBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion getSharedMemoryRegion(int index) {
        if (sharedMemoryRegionBuilder_ == null) {
          return sharedMemoryRegion_.get(index);
        } else {
          return sharedMemoryRegionBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder setSharedMemoryRegion(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion value) {
        if (sharedMemoryRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.set(index, value);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder setSharedMemoryRegion(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder builderForValue) {
        if (sharedMemoryRegionBuilder_ == null) {
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.set(index, builderForValue.build());
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder addSharedMemoryRegion(nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion value) {
        if (sharedMemoryRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.add(value);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder addSharedMemoryRegion(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion value) {
        if (sharedMemoryRegionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.add(index, value);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder addSharedMemoryRegion(
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder builderForValue) {
        if (sharedMemoryRegionBuilder_ == null) {
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.add(builderForValue.build());
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder addSharedMemoryRegion(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder builderForValue) {
        if (sharedMemoryRegionBuilder_ == null) {
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.add(index, builderForValue.build());
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder addAllSharedMemoryRegion(
          java.lang.Iterable<? extends nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion> values) {
        if (sharedMemoryRegionBuilder_ == null) {
          ensureSharedMemoryRegionIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, sharedMemoryRegion_);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder clearSharedMemoryRegion() {
        if (sharedMemoryRegionBuilder_ == null) {
          sharedMemoryRegion_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public Builder removeSharedMemoryRegion(int index) {
        if (sharedMemoryRegionBuilder_ == null) {
          ensureSharedMemoryRegionIsMutable();
          sharedMemoryRegion_.remove(index);
          onChanged();
        } else {
          sharedMemoryRegionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder getSharedMemoryRegionBuilder(
          int index) {
        return getSharedMemoryRegionFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder getSharedMemoryRegionOrBuilder(
          int index) {
        if (sharedMemoryRegionBuilder_ == null) {
          return sharedMemoryRegion_.get(index);  } else {
          return sharedMemoryRegionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder> 
           getSharedMemoryRegionOrBuilderList() {
        if (sharedMemoryRegionBuilder_ != null) {
          return sharedMemoryRegionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(sharedMemoryRegion_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder addSharedMemoryRegionBuilder() {
        return getSharedMemoryRegionFieldBuilder().addBuilder(
            nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder addSharedMemoryRegionBuilder(
          int index) {
        return getSharedMemoryRegionFieldBuilder().addBuilder(
            index, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: SharedMemoryRegion shared_memory_region (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of active/registered shared memory regions.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.SharedMemoryRegion shared_memory_region = 2;</code>
       */
      public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder> 
           getSharedMemoryRegionBuilderList() {
        return getSharedMemoryRegionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder> 
          getSharedMemoryRegionFieldBuilder() {
        if (sharedMemoryRegionBuilder_ == null) {
          sharedMemoryRegionBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegion.Builder, nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryRegionOrBuilder>(
                  sharedMemoryRegion_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          sharedMemoryRegion_ = null;
        }
        return sharedMemoryRegionBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.SharedMemoryStatus)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.SharedMemoryStatus)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SharedMemoryStatus>
        PARSER = new com.google.protobuf.AbstractParser<SharedMemoryStatus>() {
      @java.lang.Override
      public SharedMemoryStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SharedMemoryStatus(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SharedMemoryStatus> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SharedMemoryStatus> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.SharedMemoryStatus getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelRepositoryIndexOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelRepositoryIndex)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> 
        getModelsList();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getModels(int index);
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    int getModelsCount();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder> 
        getModelsOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder getModelsOrBuilder(
        int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelRepositoryIndex
   *&#64;&#64;
   *&#64;&#64;   Index of the model repository monitored by the inference server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code nvidia.inferenceserver.ModelRepositoryIndex}
   */
  public  static final class ModelRepositoryIndex extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelRepositoryIndex)
      ModelRepositoryIndexOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModelRepositoryIndex.newBuilder() to construct.
    private ModelRepositoryIndex(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelRepositoryIndex() {
      models_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModelRepositoryIndex(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                models_ = new java.util.ArrayList<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry>();
                mutable_bitField0_ |= 0x00000001;
              }
              models_.add(
                  input.readMessage(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.parser(), extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownFieldProto3(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          models_ = java.util.Collections.unmodifiableList(models_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.Builder.class);
    }

    public interface ModelEntryOrBuilder extends
        // @@protoc_insertion_point(interface_extends:nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The model's name.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      java.lang.String getName();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The model's name.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      com.google.protobuf.ByteString
          getNameBytes();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message ModelEntry
     *&#64;&#64;
     *&#64;&#64;     The basic information for a model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry}
     */
    public  static final class ModelEntry extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry)
        ModelEntryOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use ModelEntry.newBuilder() to construct.
      private ModelEntry(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private ModelEntry() {
        name_ = "";
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private ModelEntry(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                java.lang.String s = input.readStringRequireUtf8();

                name_ = s;
                break;
              }
              default: {
                if (!parseUnknownFieldProto3(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder.class);
      }

      public static final int NAME_FIELD_NUMBER = 1;
      private volatile java.lang.Object name_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The model's name.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The model's name.
       *&#64;&#64;
       * </pre>
       *
       * <code>string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!getNameBytes().isEmpty()) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!getNameBytes().isEmpty()) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry)) {
          return super.equals(obj);
        }
        nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry) obj;

        boolean result = true;
        result = result && getName()
            .equals(other.getName());
        result = result && unknownFields.equals(other.unknownFields);
        return result;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message ModelEntry
       *&#64;&#64;
       *&#64;&#64;     The basic information for a model.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry)
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder.class);
        }

        // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          name_ = "";

          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getDefaultInstanceForType() {
          return nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.getDefaultInstance();
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry build() {
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry buildPartial() {
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry(this);
          result.name_ = name_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return (Builder) super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry) {
            return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry other) {
          if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.getDefaultInstance()) return this;
          if (!other.getName().isEmpty()) {
            name_ = other.name_;
            onChanged();
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private java.lang.Object name_ = "";
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The model's name.
         *&#64;&#64;
         * </pre>
         *
         * <code>string name = 1;</code>
         */
        public java.lang.String getName() {
          java.lang.Object ref = name_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            name_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The model's name.
         *&#64;&#64;
         * </pre>
         *
         * <code>string name = 1;</code>
         */
        public com.google.protobuf.ByteString
            getNameBytes() {
          java.lang.Object ref = name_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            name_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The model's name.
         *&#64;&#64;
         * </pre>
         *
         * <code>string name = 1;</code>
         */
        public Builder setName(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  
          name_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The model's name.
         *&#64;&#64;
         * </pre>
         *
         * <code>string name = 1;</code>
         */
        public Builder clearName() {
          
          name_ = getDefaultInstance().getName();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The model's name.
         *&#64;&#64;
         * </pre>
         *
         * <code>string name = 1;</code>
         */
        public Builder setNameBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
          
          name_ = value;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFieldsProto3(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry)
      }

      // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry)
      private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry();
      }

      public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<ModelEntry>
          PARSER = new com.google.protobuf.AbstractParser<ModelEntry>() {
        @java.lang.Override
        public ModelEntry parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelEntry(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<ModelEntry> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<ModelEntry> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int MODELS_FIELD_NUMBER = 1;
    private java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> models_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> getModelsList() {
      return models_;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    public java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder> 
        getModelsOrBuilderList() {
      return models_;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    public int getModelsCount() {
      return models_.size();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getModels(int index) {
      return models_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
     *&#64;&#64;
     *&#64;&#64;     The list of models in the model repository.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
     */
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder getModelsOrBuilder(
        int index) {
      return models_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < models_.size(); i++) {
        output.writeMessage(1, models_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < models_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, models_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex)) {
        return super.equals(obj);
      }
      nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex other = (nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex) obj;

      boolean result = true;
      result = result && getModelsList()
          .equals(other.getModelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getModelsCount() > 0) {
        hash = (37 * hash) + MODELS_FIELD_NUMBER;
        hash = (53 * hash) + getModelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelRepositoryIndex
     *&#64;&#64;
     *&#64;&#64;   Index of the model repository monitored by the inference server.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code nvidia.inferenceserver.ModelRepositoryIndex}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.inferenceserver.ModelRepositoryIndex)
        nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndexOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.class, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.Builder.class);
      }

      // Construct using nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getModelsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (modelsBuilder_ == null) {
          models_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          modelsBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex getDefaultInstanceForType() {
        return nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.getDefaultInstance();
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex build() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex buildPartial() {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex result = new nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex(this);
        int from_bitField0_ = bitField0_;
        if (modelsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            models_ = java.util.Collections.unmodifiableList(models_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.models_ = models_;
        } else {
          result.models_ = modelsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return (Builder) super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex) {
          return mergeFrom((nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex other) {
        if (other == nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.getDefaultInstance()) return this;
        if (modelsBuilder_ == null) {
          if (!other.models_.isEmpty()) {
            if (models_.isEmpty()) {
              models_ = other.models_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureModelsIsMutable();
              models_.addAll(other.models_);
            }
            onChanged();
          }
        } else {
          if (!other.models_.isEmpty()) {
            if (modelsBuilder_.isEmpty()) {
              modelsBuilder_.dispose();
              modelsBuilder_ = null;
              models_ = other.models_;
              bitField0_ = (bitField0_ & ~0x00000001);
              modelsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getModelsFieldBuilder() : null;
            } else {
              modelsBuilder_.addAllMessages(other.models_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> models_ =
        java.util.Collections.emptyList();
      private void ensureModelsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          models_ = new java.util.ArrayList<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry>(models_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder> modelsBuilder_;

      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> getModelsList() {
        if (modelsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(models_);
        } else {
          return modelsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public int getModelsCount() {
        if (modelsBuilder_ == null) {
          return models_.size();
        } else {
          return modelsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry getModels(int index) {
        if (modelsBuilder_ == null) {
          return models_.get(index);
        } else {
          return modelsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder setModels(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry value) {
        if (modelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelsIsMutable();
          models_.set(index, value);
          onChanged();
        } else {
          modelsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder setModels(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder builderForValue) {
        if (modelsBuilder_ == null) {
          ensureModelsIsMutable();
          models_.set(index, builderForValue.build());
          onChanged();
        } else {
          modelsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder addModels(nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry value) {
        if (modelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelsIsMutable();
          models_.add(value);
          onChanged();
        } else {
          modelsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder addModels(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry value) {
        if (modelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelsIsMutable();
          models_.add(index, value);
          onChanged();
        } else {
          modelsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder addModels(
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder builderForValue) {
        if (modelsBuilder_ == null) {
          ensureModelsIsMutable();
          models_.add(builderForValue.build());
          onChanged();
        } else {
          modelsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder addModels(
          int index, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder builderForValue) {
        if (modelsBuilder_ == null) {
          ensureModelsIsMutable();
          models_.add(index, builderForValue.build());
          onChanged();
        } else {
          modelsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder addAllModels(
          java.lang.Iterable<? extends nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry> values) {
        if (modelsBuilder_ == null) {
          ensureModelsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, models_);
          onChanged();
        } else {
          modelsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder clearModels() {
        if (modelsBuilder_ == null) {
          models_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          modelsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public Builder removeModels(int index) {
        if (modelsBuilder_ == null) {
          ensureModelsIsMutable();
          models_.remove(index);
          onChanged();
        } else {
          modelsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder getModelsBuilder(
          int index) {
        return getModelsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder getModelsOrBuilder(
          int index) {
        if (modelsBuilder_ == null) {
          return models_.get(index);  } else {
          return modelsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public java.util.List<? extends nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder> 
           getModelsOrBuilderList() {
        if (modelsBuilder_ != null) {
          return modelsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(models_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder addModelsBuilder() {
        return getModelsFieldBuilder().addBuilder(
            nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder addModelsBuilder(
          int index) {
        return getModelsFieldBuilder().addBuilder(
            index, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: ModelEntry models (repeated)
       *&#64;&#64;
       *&#64;&#64;     The list of models in the model repository.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .nvidia.inferenceserver.ModelRepositoryIndex.ModelEntry models = 1;</code>
       */
      public java.util.List<nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder> 
           getModelsBuilderList() {
        return getModelsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder> 
          getModelsFieldBuilder() {
        if (modelsBuilder_ == null) {
          modelsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntry.Builder, nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex.ModelEntryOrBuilder>(
                  models_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          models_ = null;
        }
        return modelsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFieldsProto3(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.inferenceserver.ModelRepositoryIndex)
    }

    // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelRepositoryIndex)
    private static final nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex();
    }

    public static nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelRepositoryIndex>
        PARSER = new com.google.protobuf.AbstractParser<ModelRepositoryIndex>() {
      @java.lang.Override
      public ModelRepositoryIndex parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModelRepositoryIndex(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelRepositoryIndex> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModelRepositoryIndex> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public nvidia.inferenceserver.ServerStatusOuterClass.ModelRepositoryIndex getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_StatDuration_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_StatDuration_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_StatusRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_HealthRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelControlRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_RepositoryRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_InferRequestStats_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_InferRequestStats_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelReadyStateReason_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelVersionStatus_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelStatus_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelStatus_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_SharedMemoryRegion_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ServerStatus_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ServerStatus_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_SharedMemoryStatus_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelRepositoryIndex_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\023server_status.proto\022\026nvidia.inferences" +
      "erver\032\022model_config.proto\"4\n\014StatDuratio" +
      "n\022\r\n\005count\030\001 \001(\004\022\025\n\rtotal_time_ns\030\002 \001(\004\"" +
      "K\n\022StatusRequestStats\0225\n\007success\030\001 \001(\0132$" +
      ".nvidia.inferenceserver.StatDuration\"K\n\022" +
      "HealthRequestStats\0225\n\007success\030\001 \001(\0132$.nv" +
      "idia.inferenceserver.StatDuration\"Q\n\030Mod" +
      "elControlRequestStats\0225\n\007success\030\001 \001(\0132$" +
      ".nvidia.inferenceserver.StatDuration\"X\n\037" +
      "SharedMemoryControlRequestStats\0225\n\007succe" +
      "ss\030\001 \001(\0132$.nvidia.inferenceserver.StatDu" +
      "ration\"O\n\026RepositoryRequestStats\0225\n\007succ" +
      "ess\030\001 \001(\0132$.nvidia.inferenceserver.StatD" +
      "uration\"\354\001\n\021InferRequestStats\0225\n\007success" +
      "\030\001 \001(\0132$.nvidia.inferenceserver.StatDura" +
      "tion\0224\n\006failed\030\002 \001(\0132$.nvidia.inferences" +
      "erver.StatDuration\0225\n\007compute\030\003 \001(\0132$.nv" +
      "idia.inferenceserver.StatDuration\0223\n\005que" +
      "ue\030\004 \001(\0132$.nvidia.inferenceserver.StatDu" +
      "ration\"(\n\025ModelReadyStateReason\022\017\n\007messa" +
      "ge\030\001 \001(\t\"\271\003\n\022ModelVersionStatus\022<\n\013ready" +
      "_state\030\001 \001(\0162\'.nvidia.inferenceserver.Mo" +
      "delReadyState\022I\n\022ready_state_reason\030\005 \001(" +
      "\0132-.nvidia.inferenceserver.ModelReadySta" +
      "teReason\022O\n\013infer_stats\030\002 \003(\0132:.nvidia.i" +
      "nferenceserver.ModelVersionStatus.InferS" +
      "tatsEntry\022\035\n\025model_execution_count\030\003 \001(\004" +
      "\022\035\n\025model_inference_count\030\004 \001(\004\022-\n%last_" +
      "inference_timestamp_milliseconds\030\006 \001(\004\032\\" +
      "\n\017InferStatsEntry\022\013\n\003key\030\001 \001(\r\0228\n\005value\030" +
      "\002 \001(\0132).nvidia.inferenceserver.InferRequ" +
      "estStats:\0028\001\"\364\001\n\013ModelStatus\0223\n\006config\030\001" +
      " \001(\0132#.nvidia.inferenceserver.ModelConfi" +
      "g\022N\n\016version_status\030\002 \003(\01326.nvidia.infer" +
      "enceserver.ModelStatus.VersionStatusEntr" +
      "y\032`\n\022VersionStatusEntry\022\013\n\003key\030\001 \001(\003\0229\n\005" +
      "value\030\002 \001(\0132*.nvidia.inferenceserver.Mod" +
      "elVersionStatus:\0028\001\"\356\002\n\022SharedMemoryRegi" +
      "on\022\014\n\004name\030\001 \001(\t\022]\n\024system_shared_memory" +
      "\030\002 \001(\0132=.nvidia.inferenceserver.SharedMe" +
      "moryRegion.SystemSharedMemoryH\000\022Y\n\022cuda_" +
      "shared_memory\030\003 \001(\0132;.nvidia.inferencese" +
      "rver.SharedMemoryRegion.CudaSharedMemory" +
      "H\000\022\021\n\tbyte_size\030\005 \001(\004\032?\n\022SystemSharedMem" +
      "ory\022\031\n\021shared_memory_key\030\001 \001(\t\022\016\n\006offset" +
      "\030\002 \001(\004\032%\n\020CudaSharedMemory\022\021\n\tdevice_id\030" +
      "\001 \001(\003B\025\n\023shared_memory_types\"\224\005\n\014ServerS" +
      "tatus\022\n\n\002id\030\001 \001(\t\022\017\n\007version\030\002 \001(\t\022=\n\013re" +
      "ady_state\030\007 \001(\0162(.nvidia.inferenceserver" +
      ".ServerReadyState\022\021\n\tuptime_ns\030\003 \001(\004\022K\n\014" +
      "model_status\030\004 \003(\01325.nvidia.inferenceser" +
      "ver.ServerStatus.ModelStatusEntry\022@\n\014sta" +
      "tus_stats\030\005 \001(\0132*.nvidia.inferenceserver" +
      ".StatusRequestStats\022@\n\014health_stats\030\010 \001(" +
      "\0132*.nvidia.inferenceserver.HealthRequest" +
      "Stats\022M\n\023model_control_stats\030\t \001(\01320.nvi" +
      "dia.inferenceserver.ModelControlRequestS" +
      "tats\022R\n\021shm_control_stats\030\n \001(\01327.nvidia" +
      ".inferenceserver.SharedMemoryControlRequ" +
      "estStats\022H\n\020repository_stats\030\013 \001(\0132..nvi" +
      "dia.inferenceserver.RepositoryRequestSta" +
      "ts\032W\n\020ModelStatusEntry\022\013\n\003key\030\001 \001(\t\0222\n\005v" +
      "alue\030\002 \001(\0132#.nvidia.inferenceserver.Mode" +
      "lStatus:\0028\001\"^\n\022SharedMemoryStatus\022H\n\024sha" +
      "red_memory_region\030\002 \003(\0132*.nvidia.inferen" +
      "ceserver.SharedMemoryRegion\"{\n\024ModelRepo" +
      "sitoryIndex\022G\n\006models\030\001 \003(\01327.nvidia.inf" +
      "erenceserver.ModelRepositoryIndex.ModelE" +
      "ntry\032\032\n\nModelEntry\022\014\n\004name\030\001 \001(\t*t\n\017Mode" +
      "lReadyState\022\021\n\rMODEL_UNKNOWN\020\000\022\017\n\013MODEL_" +
      "READY\020\001\022\025\n\021MODEL_UNAVAILABLE\020\002\022\021\n\rMODEL_" +
      "LOADING\020\003\022\023\n\017MODEL_UNLOADING\020\004*\206\001\n\020Serve" +
      "rReadyState\022\022\n\016SERVER_INVALID\020\000\022\027\n\023SERVE" +
      "R_INITIALIZING\020\001\022\020\n\014SERVER_READY\020\002\022\022\n\016SE" +
      "RVER_EXITING\020\003\022\037\n\033SERVER_FAILED_TO_INITI" +
      "ALIZE\020\nb\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          nvidia.inferenceserver.ModelConfigOuterClass.getDescriptor(),
        }, assigner);
    internal_static_nvidia_inferenceserver_StatDuration_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_nvidia_inferenceserver_StatDuration_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_StatDuration_descriptor,
        new java.lang.String[] { "Count", "TotalTimeNs", });
    internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_nvidia_inferenceserver_StatusRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_StatusRequestStats_descriptor,
        new java.lang.String[] { "Success", });
    internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_nvidia_inferenceserver_HealthRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_HealthRequestStats_descriptor,
        new java.lang.String[] { "Success", });
    internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_nvidia_inferenceserver_ModelControlRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelControlRequestStats_descriptor,
        new java.lang.String[] { "Success", });
    internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_SharedMemoryControlRequestStats_descriptor,
        new java.lang.String[] { "Success", });
    internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_nvidia_inferenceserver_RepositoryRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_RepositoryRequestStats_descriptor,
        new java.lang.String[] { "Success", });
    internal_static_nvidia_inferenceserver_InferRequestStats_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_nvidia_inferenceserver_InferRequestStats_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_InferRequestStats_descriptor,
        new java.lang.String[] { "Success", "Failed", "Compute", "Queue", });
    internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_nvidia_inferenceserver_ModelReadyStateReason_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelReadyStateReason_descriptor,
        new java.lang.String[] { "Message", });
    internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_nvidia_inferenceserver_ModelVersionStatus_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor,
        new java.lang.String[] { "ReadyState", "ReadyStateReason", "InferStats", "ModelExecutionCount", "ModelInferenceCount", "LastInferenceTimestampMilliseconds", });
    internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_descriptor =
      internal_static_nvidia_inferenceserver_ModelVersionStatus_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelVersionStatus_InferStatsEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_nvidia_inferenceserver_ModelStatus_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_nvidia_inferenceserver_ModelStatus_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelStatus_descriptor,
        new java.lang.String[] { "Config", "VersionStatus", });
    internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_descriptor =
      internal_static_nvidia_inferenceserver_ModelStatus_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelStatus_VersionStatusEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor,
        new java.lang.String[] { "Name", "SystemSharedMemory", "CudaSharedMemory", "ByteSize", "SharedMemoryTypes", });
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor =
      internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_SharedMemoryRegion_SystemSharedMemory_descriptor,
        new java.lang.String[] { "SharedMemoryKey", "Offset", });
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor =
      internal_static_nvidia_inferenceserver_SharedMemoryRegion_descriptor.getNestedTypes().get(1);
    internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_SharedMemoryRegion_CudaSharedMemory_descriptor,
        new java.lang.String[] { "DeviceId", });
    internal_static_nvidia_inferenceserver_ServerStatus_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_nvidia_inferenceserver_ServerStatus_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ServerStatus_descriptor,
        new java.lang.String[] { "Id", "Version", "ReadyState", "UptimeNs", "ModelStatus", "StatusStats", "HealthStats", "ModelControlStats", "ShmControlStats", "RepositoryStats", });
    internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_descriptor =
      internal_static_nvidia_inferenceserver_ServerStatus_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ServerStatus_ModelStatusEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_nvidia_inferenceserver_SharedMemoryStatus_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_SharedMemoryStatus_descriptor,
        new java.lang.String[] { "SharedMemoryRegion", });
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor,
        new java.lang.String[] { "Models", });
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor =
      internal_static_nvidia_inferenceserver_ModelRepositoryIndex_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_inferenceserver_ModelRepositoryIndex_ModelEntry_descriptor,
        new java.lang.String[] { "Name", });
    nvidia.inferenceserver.ModelConfigOuterClass.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
